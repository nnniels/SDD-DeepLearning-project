{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyO1HEBNsJDAuwSXBd/Jwm/K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9d0eed2471ca42d899ab4a8fb8e31eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b830055b7c1b40e18a13a0fb289779fc",
              "IPY_MODEL_b4c454240c174419a4c07915ae8cbfa7",
              "IPY_MODEL_12fb7ae985af4942b1bed621b376d6d4"
            ],
            "layout": "IPY_MODEL_2c7df8d07ce247669f675ace5076bd85"
          }
        },
        "b830055b7c1b40e18a13a0fb289779fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1242cb6327b4c71b1272673ebe4c4cb",
            "placeholder": "​",
            "style": "IPY_MODEL_75d05405fede451d980aba5feaa00252",
            "value": "100%"
          }
        },
        "b4c454240c174419a4c07915ae8cbfa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34402435f7d647caa6a826c99ca3ef34",
            "max": 4000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35eb5d5cf87e41a0aed468d386979fe2",
            "value": 4000
          }
        },
        "12fb7ae985af4942b1bed621b376d6d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6b7fe56802f4f4fb8532b78796764b6",
            "placeholder": "​",
            "style": "IPY_MODEL_eee095f12532487f845526491989a1c7",
            "value": " 4000/4000 [21:18&lt;00:00,  2.69s/it]"
          }
        },
        "2c7df8d07ce247669f675ace5076bd85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1242cb6327b4c71b1272673ebe4c4cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75d05405fede451d980aba5feaa00252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34402435f7d647caa6a826c99ca3ef34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35eb5d5cf87e41a0aed468d386979fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6b7fe56802f4f4fb8532b78796764b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eee095f12532487f845526491989a1c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nnniels/SDD-DeepLearning-project/blob/main/SLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python imports"
      ],
      "metadata": {
        "id": "TFlAYGKWsqKI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "Kx1yfH_usBxR"
      },
      "outputs": [],
      "source": [
        "# generic libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "# torch-related libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "# hugging face dataset downloader\n",
        "import datasets\n",
        "# tokenizer (?)\n",
        "import tiktoken\n",
        "# show progress bar in loop\n",
        "from tqdm.auto import tqdm\n",
        "# colab download file\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading"
      ],
      "metadata": {
        "id": "GKhKv6ejsu_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = datasets.load_dataset(\"ahmad543/genre_stories\")"
      ],
      "metadata": {
        "id": "3eyiD9YcsxhR"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer"
      ],
      "metadata": {
        "id": "GDInNVVaut6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# uses a pre-otkenized teokenizer (?)\n",
        "enc = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "mCE44MkEtObf"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters"
      ],
      "metadata": {
        "id": "4mBqKi-gwAF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using device: {device}')\n",
        "print(f'PyTorch version: {torch.__version__}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tllk9bsJ0srt",
        "outputId": "d6d6fb86-49c4-4f24-f2f3-5868e8bb9489"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "PyTorch version: 2.9.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Model hyperparameters\n",
        "class Config:\n",
        "    # Vocabulary\n",
        "    vocab_size = enc.n_vocab\n",
        "    n_embd = 384\n",
        "    # Model architecture\n",
        "    d_model = 384          # Embedding dimension ??\n",
        "    n_heads = 6            # Number of attention heads\n",
        "    n_layers = 6           # Number of transformer blocks o:4\n",
        "    d_ff = 1024             # Feed-forward dimension\n",
        "    dropout = 0.1          # Dropout rate\n",
        "\n",
        "    # Training\n",
        "    block_size = 128        # Maximum context length\n",
        "    batch_size = 32        # Batch size\n",
        "    learning_rate = 3e-4   # Learning rate\n",
        "    max_iters = 4000       # Training iterations o:3000\n",
        "    eval_interval = 100    # Evaluate every N iterations\n",
        "    eval_iters = 50       # Number of iterations for evaluation\n",
        "\n",
        "config = Config()"
      ],
      "metadata": {
        "id": "V3waJMyQwCSL"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def auto_lr(iter, i1=1000, v1=2e-4, i2=20000, v2=5e-5):\n",
        "  if iter < i1:\n",
        "    # augment from 0 to v0\n",
        "    beta = np.arccos((v1))/(i1)\n",
        "    return v1*np.cos(beta*(iter-i1))\n",
        "    #return iter/1000*v1\n",
        "  elif iter < i2:\n",
        "    # diminish learning rate following cosine curve\n",
        "    beta = np.arccos((v2/v1))/(i2-i1)\n",
        "    return v1*np.cos(beta*(iter-i1))\n",
        "  else:\n",
        "    return v1\n",
        "\n",
        "lr_iter = []\n",
        "for k in range(config.max_iters):\n",
        "  lr_iter.append(auto_lr(k, i1=config.max_iters//10, i2=config.max_iters, v1=4e-4, v2=1e-4))\n",
        "\n",
        "figure = px.line(x=range(config.max_iters), y=lr_iter, labels={'x': 'Iteration', 'y': 'Learning Rate'}, title='Learning Rate')\n",
        "figure.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "0j2jAzVBVePh",
        "outputId": "85480b1f-7f9a-4478-cb93-0ad55334b745"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"68eca714-6f92-4464-80f5-9111f7c3e6c1\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"68eca714-6f92-4464-80f5-9111f7c3e6c1\")) {                    Plotly.newPlot(                        \"68eca714-6f92-4464-80f5-9111f7c3e6c1\",                        [{\"hovertemplate\":\"Iteration=%{x}\\u003cbr\\u003eLearning Rate=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2396,2397,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2493,2494,2495,2496,2497,2498,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2572,2573,2574,2575,2576,2577,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,2591,2592,2593,2594,2595,2596,2597,2598,2599,2600,2601,2602,2603,2604,2605,2606,2607,2608,2609,2610,2611,2612,2613,2614,2615,2616,2617,2618,2619,2620,2621,2622,2623,2624,2625,2626,2627,2628,2629,2630,2631,2632,2633,2634,2635,2636,2637,2638,2639,2640,2641,2642,2643,2644,2645,2646,2647,2648,2649,2650,2651,2652,2653,2654,2655,2656,2657,2658,2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,2671,2672,2673,2674,2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,2691,2692,2693,2694,2695,2696,2697,2698,2699,2700,2701,2702,2703,2704,2705,2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,2731,2732,2733,2734,2735,2736,2737,2738,2739,2740,2741,2742,2743,2744,2745,2746,2747,2748,2749,2750,2751,2752,2753,2754,2755,2756,2757,2758,2759,2760,2761,2762,2763,2764,2765,2766,2767,2768,2769,2770,2771,2772,2773,2774,2775,2776,2777,2778,2779,2780,2781,2782,2783,2784,2785,2786,2787,2788,2789,2790,2791,2792,2793,2794,2795,2796,2797,2798,2799,2800,2801,2802,2803,2804,2805,2806,2807,2808,2809,2810,2811,2812,2813,2814,2815,2816,2817,2818,2819,2820,2821,2822,2823,2824,2825,2826,2827,2828,2829,2830,2831,2832,2833,2834,2835,2836,2837,2838,2839,2840,2841,2842,2843,2844,2845,2846,2847,2848,2849,2850,2851,2852,2853,2854,2855,2856,2857,2858,2859,2860,2861,2862,2863,2864,2865,2866,2867,2868,2869,2870,2871,2872,2873,2874,2875,2876,2877,2878,2879,2880,2881,2882,2883,2884,2885,2886,2887,2888,2889,2890,2891,2892,2893,2894,2895,2896,2897,2898,2899,2900,2901,2902,2903,2904,2905,2906,2907,2908,2909,2910,2911,2912,2913,2914,2915,2916,2917,2918,2919,2920,2921,2922,2923,2924,2925,2926,2927,2928,2929,2930,2931,2932,2933,2934,2935,2936,2937,2938,2939,2940,2941,2942,2943,2944,2945,2946,2947,2948,2949,2950,2951,2952,2953,2954,2955,2956,2957,2958,2959,2960,2961,2962,2963,2964,2965,2966,2967,2968,2969,2970,2971,2972,2973,2974,2975,2976,2977,2978,2979,2980,2981,2982,2983,2984,2985,2986,2987,2988,2989,2990,2991,2992,2993,2994,2995,2996,2997,2998,2999,3000,3001,3002,3003,3004,3005,3006,3007,3008,3009,3010,3011,3012,3013,3014,3015,3016,3017,3018,3019,3020,3021,3022,3023,3024,3025,3026,3027,3028,3029,3030,3031,3032,3033,3034,3035,3036,3037,3038,3039,3040,3041,3042,3043,3044,3045,3046,3047,3048,3049,3050,3051,3052,3053,3054,3055,3056,3057,3058,3059,3060,3061,3062,3063,3064,3065,3066,3067,3068,3069,3070,3071,3072,3073,3074,3075,3076,3077,3078,3079,3080,3081,3082,3083,3084,3085,3086,3087,3088,3089,3090,3091,3092,3093,3094,3095,3096,3097,3098,3099,3100,3101,3102,3103,3104,3105,3106,3107,3108,3109,3110,3111,3112,3113,3114,3115,3116,3117,3118,3119,3120,3121,3122,3123,3124,3125,3126,3127,3128,3129,3130,3131,3132,3133,3134,3135,3136,3137,3138,3139,3140,3141,3142,3143,3144,3145,3146,3147,3148,3149,3150,3151,3152,3153,3154,3155,3156,3157,3158,3159,3160,3161,3162,3163,3164,3165,3166,3167,3168,3169,3170,3171,3172,3173,3174,3175,3176,3177,3178,3179,3180,3181,3182,3183,3184,3185,3186,3187,3188,3189,3190,3191,3192,3193,3194,3195,3196,3197,3198,3199,3200,3201,3202,3203,3204,3205,3206,3207,3208,3209,3210,3211,3212,3213,3214,3215,3216,3217,3218,3219,3220,3221,3222,3223,3224,3225,3226,3227,3228,3229,3230,3231,3232,3233,3234,3235,3236,3237,3238,3239,3240,3241,3242,3243,3244,3245,3246,3247,3248,3249,3250,3251,3252,3253,3254,3255,3256,3257,3258,3259,3260,3261,3262,3263,3264,3265,3266,3267,3268,3269,3270,3271,3272,3273,3274,3275,3276,3277,3278,3279,3280,3281,3282,3283,3284,3285,3286,3287,3288,3289,3290,3291,3292,3293,3294,3295,3296,3297,3298,3299,3300,3301,3302,3303,3304,3305,3306,3307,3308,3309,3310,3311,3312,3313,3314,3315,3316,3317,3318,3319,3320,3321,3322,3323,3324,3325,3326,3327,3328,3329,3330,3331,3332,3333,3334,3335,3336,3337,3338,3339,3340,3341,3342,3343,3344,3345,3346,3347,3348,3349,3350,3351,3352,3353,3354,3355,3356,3357,3358,3359,3360,3361,3362,3363,3364,3365,3366,3367,3368,3369,3370,3371,3372,3373,3374,3375,3376,3377,3378,3379,3380,3381,3382,3383,3384,3385,3386,3387,3388,3389,3390,3391,3392,3393,3394,3395,3396,3397,3398,3399,3400,3401,3402,3403,3404,3405,3406,3407,3408,3409,3410,3411,3412,3413,3414,3415,3416,3417,3418,3419,3420,3421,3422,3423,3424,3425,3426,3427,3428,3429,3430,3431,3432,3433,3434,3435,3436,3437,3438,3439,3440,3441,3442,3443,3444,3445,3446,3447,3448,3449,3450,3451,3452,3453,3454,3455,3456,3457,3458,3459,3460,3461,3462,3463,3464,3465,3466,3467,3468,3469,3470,3471,3472,3473,3474,3475,3476,3477,3478,3479,3480,3481,3482,3483,3484,3485,3486,3487,3488,3489,3490,3491,3492,3493,3494,3495,3496,3497,3498,3499,3500,3501,3502,3503,3504,3505,3506,3507,3508,3509,3510,3511,3512,3513,3514,3515,3516,3517,3518,3519,3520,3521,3522,3523,3524,3525,3526,3527,3528,3529,3530,3531,3532,3533,3534,3535,3536,3537,3538,3539,3540,3541,3542,3543,3544,3545,3546,3547,3548,3549,3550,3551,3552,3553,3554,3555,3556,3557,3558,3559,3560,3561,3562,3563,3564,3565,3566,3567,3568,3569,3570,3571,3572,3573,3574,3575,3576,3577,3578,3579,3580,3581,3582,3583,3584,3585,3586,3587,3588,3589,3590,3591,3592,3593,3594,3595,3596,3597,3598,3599,3600,3601,3602,3603,3604,3605,3606,3607,3608,3609,3610,3611,3612,3613,3614,3615,3616,3617,3618,3619,3620,3621,3622,3623,3624,3625,3626,3627,3628,3629,3630,3631,3632,3633,3634,3635,3636,3637,3638,3639,3640,3641,3642,3643,3644,3645,3646,3647,3648,3649,3650,3651,3652,3653,3654,3655,3656,3657,3658,3659,3660,3661,3662,3663,3664,3665,3666,3667,3668,3669,3670,3671,3672,3673,3674,3675,3676,3677,3678,3679,3680,3681,3682,3683,3684,3685,3686,3687,3688,3689,3690,3691,3692,3693,3694,3695,3696,3697,3698,3699,3700,3701,3702,3703,3704,3705,3706,3707,3708,3709,3710,3711,3712,3713,3714,3715,3716,3717,3718,3719,3720,3721,3722,3723,3724,3725,3726,3727,3728,3729,3730,3731,3732,3733,3734,3735,3736,3737,3738,3739,3740,3741,3742,3743,3744,3745,3746,3747,3748,3749,3750,3751,3752,3753,3754,3755,3756,3757,3758,3759,3760,3761,3762,3763,3764,3765,3766,3767,3768,3769,3770,3771,3772,3773,3774,3775,3776,3777,3778,3779,3780,3781,3782,3783,3784,3785,3786,3787,3788,3789,3790,3791,3792,3793,3794,3795,3796,3797,3798,3799,3800,3801,3802,3803,3804,3805,3806,3807,3808,3809,3810,3811,3812,3813,3814,3815,3816,3817,3818,3819,3820,3821,3822,3823,3824,3825,3826,3827,3828,3829,3830,3831,3832,3833,3834,3835,3836,3837,3838,3839,3840,3841,3842,3843,3844,3845,3846,3847,3848,3849,3850,3851,3852,3853,3854,3855,3856,3857,3858,3859,3860,3861,3862,3863,3864,3865,3866,3867,3868,3869,3870,3871,3872,3873,3874,3875,3876,3877,3878,3879,3880,3881,3882,3883,3884,3885,3886,3887,3888,3889,3890,3891,3892,3893,3894,3895,3896,3897,3898,3899,3900,3901,3902,3903,3904,3905,3906,3907,3908,3909,3910,3911,3912,3913,3914,3915,3916,3917,3918,3919,3920,3921,3922,3923,3924,3925,3926,3927,3928,3929,3930,3931,3932,3933,3934,3935,3936,3937,3938,3939,3940,3941,3942,3943,3944,3945,3946,3947,3948,3949,3950,3951,3952,3953,3954,3955,3956,3957,3958,3959,3960,3961,3962,3963,3964,3965,3966,3967,3968,3969,3970,3971,3972,3973,3974,3975,3976,3977,3978,3979,3980,3981,3982,3983,3984,3985,3986,3987,3988,3989,3990,3991,3992,3993,3994,3995,3996,3997,3998,3999],\"xaxis\":\"x\",\"y\":[1.5999999999988258e-7,1.7303909338929947e-6,3.300755196606004e-6,4.871068583511269e-6,6.441306890765582e-6,8.011445915682612e-6,9.581461457106657e-6,0.000011151329315785054,0.000012721025294741424,0.000014290525199648905,0.000015859804839202535,0.000017428840025492386,0.000018997606574376642,0.000020566080305853844,0.00002213423704443583,0.000023702052619520643,0.000025269502865764537,0.000026836563623454737,0.000028403210738882046,0.000029969420064712554,0.00003153516746036053,0.00003310042879235987,0.00003466517993473636,0.00003622939676937982,0.00003779305518641526,0.00003935613108457483,0.00004091860037156949,0.000042480438964459915,0.000044041622790027876,0.000045602127785147604,0.00004716192989715604,0.00004872100508422431,0.000050279329315727605,0.000051836878572615934,0.0000533936288477845,0.000054949556146443316,0.000056504636486487186,0.00005805884589886571,0.00005961216042795216,0.00006116455613191298,0.0000627160090830771,0.0000642664953683041,0.0000658159910893535,0.0000673644723632525,0.00006891191532266439,0.00007045829611625663,0.00007200359090906798,0.00007354777588287621,0.00007509082723656536,0.00007663272118649212,0.00007817343396685275,0.00007971294183004956,0.00008125122104705634,0.00008278824790778484,0.00008432399872144962,0.00008585844981693339,0.00008739157754315226,0.0000889233582694196,0.00009045376838581064,0.0000919827843035266,0.00009351038245525776,0.000095036539295547,0.00009656123130115289,0.00009808443497141176,0.00009960612682860057,0.00010112628341829813,0.00010264488130974697,0.00010416189709621465,0.00010567730739535411,0.00010719108884956426,0.00010870321812635027,0.00011021367191868268,0.000111722426945357,0.00011322945995135261,0.00011473474770819082,0.00011623826701429339,0.00011773999469533968,0.00011923990760462404,0.00012073798262341289,0.00012223419666130048,0.000123728526656565,0.00012522094957652448,0.00012671144241789114,0.00012819998220712624,0.00012968654600079441,0.00013117111088591676,0.00013265365398032467,0.00013413415243301188,0.00013561258342448704,0.00013708892416712553,0.00013856315190552038,0.00014003524391683313,0.00014150517751114434,0.00014297293003180284,0.00014443847885577517,0.00014590180139399458,0.00014736287509170857,0.0001488216774288272,0.00015027818592026963,0.00015173237811631098,0.00015318423160292854,0.00015463372400214678,0.0001560808329723825,0.00015752553620878955,0.00015896781144360186,0.00016040763644647728,0.0001618449890248401,0.0001632798470242228,0.00016471218832860807,0.00016614199086076916,0.00016756923258261038,0.000168993891495507,0.00017041594564064396,0.0001718353730993544,0.00017325215199345785,0.000174666260485597,0.00017607767677957437,0.00017748637912068873,0.0001788923457960696,0.00018029555513501274,0.0001816959855093136,0.0001830936153336008,0.00018448842306566923,0.00018588038720681148,0.0001872694863021495,0.00018865569894096557,0.00019003900375703177,0.0001914193794289395,0.0001927968046804286,0.00019417125828071432,0.00019554271904481565,0.00019691116583388094,0.00019827657755551415,0.0001996389331641001,0.00020099821166112846,0.0002023543920955176,0.0002037074535639377,0.00020505737521113253,0.00020640413623024126,0.0002077477158631191,0.00020908809340065693,0.0002104252481831012,0.00021175915960037141,0.00021308980709237857,0.0002144171701493419,0.00021574122831210474,0.00021706196117244995,0.00021837934837341477,0.00021969336960960418,0.00022100400462750423,0.000222311233225794,0.00022361503525565693,0.00022491539062109155,0.00022621227927922122,0.00022750568124060285,0.00022879557656953523,0.00023008194538436626,0.00023136476785779925,0.0002326440242171987,0.00023391969474489494,0.00023519175977848824,0.00023646019971115166,0.00023772499499193317,0.00023898612612605738,0.00024024357367522577,0.00024149731825791625,0.00024274734054968199,0.0002439936212834492,0.00024523614124981444,0.00024647488129734006,0.0002477098223328499,0.0002489409453217236,0.0002501682312881895,0.0002513916613156176,0.0002526112165468111,0.0002538268781842967,0.00025503862749061466,0.0002562464457886076,0.00025745031446170797,0.00025865021495422567,0.0002598461287716335,0.00026103803748085236,0.00026222592271053557,0.00026340976615135187,0.00026458954955626754,0.00026576525474082777,0.000266936863583437,0.00026810435802563824,0.00026926772007239105,0.00027042693179234943,0.00027158197531813795,0.0002727328328466269,0.00027387948663920743,0.00027502191902206404,0.0002761601123864476,0.0002772940491889466,0.00027842371195175767,0.00027954908326295467,0.0002806701457767574,0.0002817868822137986,0.00028289927536139073,0.00028400730807379094,0.0002851109632724654,0.0002862102239463527,0.00028730507315212565,0.00028839549401445325,0.00028948146972625953,0.000290562983548984,0.00029164001881283873,0.0002927125589170653,0.0002937805873301912,0.0002948440875902844,0.0002959030433052067,0.0002969574381528671,0.0002980072558814728,0.00029905248030977975,0.0003000930953273426,0.00030112908489476225,0.00030216043304393355,0.0003031871238782914,0.0003042091415730557,0.000305226470375475,0.0003062390946050698,0.0003072469986538739,0.00030825016698667507,0.0003092485841412545,0.00031024223472862506,0.0003112311034332686,0.0003122151750133719,0.0003131944343010618,0.0003141688662026388,0.0003151384556988096,0.00031610318784491896,0.0003170630477711797,0.00031801802068290227,0.00031896809186072214,0.0003199132466608274,0.0003208534705151842,0.00032178874893176105,0.0003227190674947525,0.0003236444118648011,0.00032456476777921884,0.00032548012105220635,0.0003263904575750721,0.00032729576331644967,0.00032819602432251384,0.000329091226717196,0.00032998135670239773,0.00033086640055820377,0.00033174634464309315,0.00033262117539414974,0.00033349087932727113,0.0003343554430373766,0.00033521485319861356,0.0003360690965645631,0.00033691815996844405,0.00033776203032331626,0.0003386006946222816,0.00033943413993868515,0.0003402623534263142,0.00034108532231959607,0.00034190303393379513,0.0003427154756652082,0.0003435226349913589,0.0003443244994711903,0.00034512105674525736,0.0003459122945359168,0.00034669820064751666,0.0003474787629665841,0.0003482539694620124,0.000349023808185246,0.00034978826727046506,0.00035054733493476795,0.00035130099947835335,0.00035204924928470004,0.0003527920728207464,0.00035352945863706794,0.00035426139536805386,0.0003549878717320822,0.00035570887653169373,0.00035642439865376456,0.0003571344270696773,0.0003578389508354913,0.0003585379590921112,0.00035923144106545424,0.0003599193860666163,0.0003606017834920369,0.0003612786228236626,0.0003619498936291085,0.00036261558556182,0.00036327568836123166,0.0003639301918529254,0.0003645790859487877,0.0003652223606471644,0.0003658600060330156,0.0003664920122780681,0.00036711836964096675,0.00036773906846742505,0.00036835409919037357,0.0003689634523301075,0.00036956711849443286,0.00037016508837881115,0.000370757352766503,0.0003713439025287098,0.0003719247286247148,0.0003724998221020223,0.00037306917409649564,0.0003736327758324938,0.0003741906186230068,0.00037474269386978944,0.0003752889930634939,0.0003758295077838008,0.00037636422969954917,0.00037689315056886483,0.0003774162622392872,0.00037793355664789515,0.0003784450258214313,0.00037895066187642484,0.000379450457019313,0.0003799444035465613,0.00038043249384478217,0.00038091472039085243,0.000381391075752029,0.00038186155258606387,0.0003823261436413168,0.00038278484175686733,0.00038323763986262537,0.0003836845309794397,0.00038412550821920595,0.0003845605647849725,0.0003849896939710454,0.00038541288916309175,0.00038583014383824143,0.00038624145156518786,0.0003866468060042871,0.00038704620090765547,0.00038743963011926596,0.00038782708757504296,0.0003882085673029558,0.00038858406342311114,0.0003889535701478428,0.00038931708178180195,0.000389674592722044,0.0003900260974581155,0.00039037159057213897,0.0003907110667388964,0.0003910445207259112,0.00039137194739352887,0.0003916933416949966,0.0003920086986765405,0.00039231801347744226,0.0003926212813301141,0.0003929184975601721,0.00039320965758650835,0.0003934947569213615,0.000393773791170386,0.00039404675603271983,0.00039431364730105074,0.00039457446086168103,0.00039482919269459116,0.00039507783887350156,0.0003953203955659331,0.0003955568590332664,0.00039578722563079913,0.0003960114918078025,0.0003962296541075757,0.00039644170916749955,0.0003966476537190879,0.0003968474845880382,0.0003970411986942806,0.0003972287930520251,0.00039741026476980786,0.00039758561105053563,0.00039775482919152875,0.0003979179165845631,0.00039807487071591,0.00039822568916637516,0.0003983703696113358,0.00039850890982077677,0.0003986413076593245,0.00039876756108628037,0.0003988876681556517,0.0003990016270161821,0.00039910943591138,0.00039921109317954536,0.0003993065972537958,0.0003993959466620901,0.0003994791400272518,0.0003995561760669894,0.0003996270535939169,0.00039969177151557184,0.0003997503288344319,0.0003998027246479307,0.0003998489581484714,0.00039988902862343935,0.0003999229354552129,0.00039995067812117303,0.0003999722561937114,0.0003999876693402368,0.0003999969173231806,0.0004,0.00039999997318780926,0.0003999998927512407,0.0003999997586903051,0.0003999995710050203,0.00039999932969541165,0.0003999990347615114,0.00039999868620335904,0.00039999828402100137,0.00039999782821449235,0.000399997318783893,0.0003999967557292717,0.00039999613905070385,0.00039999546874827207,0.0003999947448220664,0.0003999939672721838,0.0003999931360987285,0.0003999922513018119,0.00039999131288155263,0.00039999032083807656,0.0003999892751715166,0.000399988175882013,0.0003999870229697131,0.00039998581643477146,0.00039998455627734985,0.00039998324249761717,0.0003999818750957496,0.00039998045407193037,0.0003999789794263501,0.00039997745115920633,0.00039997586927070414,0.00039997423376105537,0.0003999725446304795,0.00039997080187920283,0.00039996900550745904,0.000399967155515489,0.0003999652519035406,0.0003999632946718692,0.000399961283820737,0.0003999592193504137,0.00039995710126117614,0.0003999549295533081,0.0003999527042271008,0.0003999504252828526,0.0003999480927208689,0.0003999457065414626,0.0003999432667449534,0.0003999407733316685,0.00039993822630194216,0.0003999356256561158,0.00039993297139453803,0.0003999302635175648,0.00039992750202555904,0.0003999246869188909,0.00039992181819793797,0.00039991889586308465,0.0003999159199147228,0.00039991289035325135,0.00039990980717907645,0.00039990667039261144,0.00039990347999427687,0.00039990023598450035,0.0003998969383637169,0.0003998935871323685,0.0003998901822909045,0.0003998867238397813,0.00039988321177946253,0.00039987964611041914,0.00039987602683312894,0.00039987235394807735,0.0003998686274557566,0.0003998648473566664,0.0003998610136513134,0.0003998571263402116,0.0003998531854238821,0.0003998491909028533,0.00039984514277766064,0.00039984104104884684,0.0003998368857169618,0.00039983267678256253,0.0003998284142462133,0.00039982409810848565,0.0003998197283699581,0.0003998153050312164,0.00039981082809285374,0.00039980629755547017,0.0003998017134196731,0.000399797075686077,0.00039979238435530377,0.0003997876394279822,0.00039978284090474845,0.0003997779887862458,0.00039977308307312474,0.0003997681237660429,0.0003997631108656652,0.00039975804437266364,0.0003997529242877174,0.00039974775061151293,0.0003997425233447438,0.0003997372424881108,0.00039973190804232185,0.00039972652000809213,0.000399721078386144,0.00039971558317720686,0.0003997100343820174,0.00039970443200131967,0.00039969877603586456,0.0003996930664864104,0.0003996873033537226,0.00039968148663857377,0.00039967561634174364,0.0003996696924640193,0.0003996637150061948,0.0003996576839690716,0.00039965159935345814,0.0003996454611601701,0.0003996392693900305,0.00039963302404386937,0.00039962672512252386,0.0003996203726268385,0.0003996139665576649,0.0003996075069158619,0.0003996009937022954,0.0003995944269178386,0.00039958780656337194,0.0003995811326397828,0.00039957440514796605,0.00039956762408882346,0.00039956078946326416,0.00039955390127220436,0.00039954695951656757,0.0003995399641972843,0.0003995329153152925,0.0003995258128715371,0.0003995186568669701,0.0003995114473025511,0.00039950418417924647,0.00039949686749802984,0.00039948949725988225,0.0003994820734657917,0.00039947459611675343,0.00039946706521376985,0.00039945948075785053,0.00039945184275001235,0.00039944415119127916,0.00039943640608268216,0.0003994286074252596,0.0003994207552200571,0.0003994128494681272,0.00039940489017052986,0.00039939687732833205,0.00039938881094260797,0.00039938069101443904,0.0003993725175449138,0.00039936429053512805,0.0003993560099861846,0.0003993476758991937,0.0003993392882752725,0.00039933084711554545,0.00039932235242114427,0.0003993138041932078,0.00039930520243288184,0.00039929654714131966,0.00039928783831968165,0.0003992790759691352,0.0003992702600908551,0.0003992613906860232,0.0003992524677558285,0.0003992434913014672,0.0003992344613241428,0.00039922537782506574,0.00039921624080545385,0.000399207050266532,0.0003991978062095323,0.000399188508635694,0.00039917915754626357,0.0003991697529424946,0.0003991602948256479,0.0003991507831969915,0.0003991412180578004,0.00039913159940935695,0.0003991219272529507,0.0003991122015898783,0.00039910242242144345,0.00039909258974895733,0.00039908270357373805,0.000399072763897111,0.00039906277072040855,0.00039905272404497057,0.00039904262387214384,0.0003990324702032824,0.00039902226303974755,0.00039901200238290753,0.000399001688234138,0.0003989913205948216,0.00039898089946634836,0.00039897042485011517,0.0003989598967475264,0.00039894931515999343,0.0003989386800889348,0.00039892799153577627,0.00039891724950195077,0.00039890645398889843,0.0003988956049980664,0.0003988847025309092,0.0003988737465888884,0.00039886273717347275,0.0003988516742861382,0.0003988405579283678,0.0003988293881016519,0.0003988181648074879,0.0003988068880473804,0.0003987955578228412,0.00039878417413538917,0.0003987727369865505,0.0003987612463778584,0.00039874970231085335,0.00039873810478708297,0.00039872645380810206,0.0003987147493754724,0.0003987029914907633,0.0003986911801555509,0.0003986793153714188,0.0003986673971399574,0.00039865542546276456,0.00039864340034144523,0.0003986313217776115,0.00039861918977288264,0.000398607004328885,0.00039859476544725235,0.00039858247312962524,0.0003985701273776517,0.0003985577281929869,0.0003985452755772929,0.00039853276953223914,0.0003985202100595023,0.0003985075971607661,0.00039849493083772135,0.0003984822110920662,0.0003984694379255058,0.0003984566113397526,0.000398443731336526,0.00039843079791755296,0.0003984178110845671,0.0003984047708393096,0.00039839167718352855,0.0003983785301189793,0.0003983653296474245,0.0003983520757706337,0.0003983387684903837,0.0003983254078084586,0.0003983119937266494,0.0003982985262467545,0.0003982850053705793,0.0003982714310999366,0.00039825780343664594,0.0003982441223825344,0.00039823038793943607,0.00039821660010919206,0.000398202758893651,0.00039818886429466834,0.0003981749163141068,0.0003981609149538362,0.0003981468602157337,0.00039813275210168344,0.0003981185906135768,0.0003981043757533122,0.0003980901075227954,0.00039807578592393906,0.00039806141095866327,0.0003980469826288952,0.000398032500936569,0.0003980179658836262,0.0003980033774720153,0.00039798873570369203,0.00039797404058061937,0.0003979592921047673,0.00039794449027811304,0.00039792963510264093,0.0003979147265803424,0.00039789976471321626,0.0003978847495032682,0.00039786968095251114,0.00039785455906296525,0.00039783938383665775,0.0003978241552756231,0.0003978088733819028,0.00039779353815754556,0.0003977781496046073,0.00039776270772515096,0.0003977472125212467,0.0003977316639949718,0.00039771606214841076,0.0003977004069836552,0.00039768469850280376,0.0003976689367079624,0.0003976531216012442,0.00039763725318476927,0.00039762133146066503,0.00039760535643106585,0.00039758932809811346,0.0003975732464639566,0.00039755711153075115,0.00039754092330066026,0.0003975246817758541,0.0003975083869585099,0.00039749203885081243,0.0003974756374549531,0.00039745918277313074,0.00039744267480755133,0.0003974261135604279,0.0003974094990339808,0.0003973928312304371,0.00039737611015203166,0.00039735933580100583,0.0003973425081796086,0.00039732562729009576,0.0003973086931347304,0.0003972917057157828,0.00039727466503553026,0.00039725757109625723,0.0003972404239002555,0.00039722322344982363,0.00039720596974726765,0.00039718866279490054,0.0003971713025950426,0.000397153889150021,0.00039713642246217036,0.0003971189025338322,0.0003971013293673552,0.0003970837029650953,0.0003970660233294156,0.00039704829046268613,0.0003970305043672842,0.0003970126650455942,0.00039699477250000777,0.00039697682673292355,0.00039695882774674733,0.00039694077554389216,0.0003969226701267781,0.0003969045114978323,0.0003968862996594893,0.0003968680346141904,0.0003968497163643844,0.00039683134491252687,0.00039681292026108085,0.00039679444241251635,0.0003967759113693105,0.0003967573271339476,0.0003967386897089191,0.0003967199990967235,0.0003967012552998665,0.0003966824583208609,0.00039666360816222664,0.0003966447048264908,0.0003966257483161876,0.00039660673863385837,0.0003965876757820515,0.0003965685597633227,0.00039654939058023455,0.00039653016823535693,0.0003965108927312668,0.00039649156407054825,0.0003964721822557926,0.0003964527472895981,0.00039643325917457017,0.00039641371791332154,0.0003963941235084718,0.00039637447596264783,0.0003963547752784837,0.00039633502145862035,0.0003963152145057061,0.00039629535442239634,0.00039627544121135334,0.0003962554748752468,0.00039623545541675345,0.00039621538283855713,0.00039619525714334867,0.00039617507833382626,0.00039615484641269505,0.0003961345613826673,0.0003961142232464626,0.0003960938320068073,0.00039607338766643513,0.0003960528902280869,0.00039603233969451063,0.00039601173606846116,0.00039599107935270073,0.00039597036954999856,0.00039594960666313107,0.0003959287906948817,0.00039590792164804106,0.00039588699952540696,0.0003958660243297841,0.00039584499606398456,0.0003958239147308274,0.0003958027803331387,0.0003957815928737518,0.00039576035235550723,0.00039573905878125237,0.0003957177121538419,0.00039569631247613754,0.0003956748597510082,0.00039565335398132986,0.0003956317951699856,0.00039561018331986554,0.00039558851843386707,0.0003955668005148946,0.0003955450295658596,0.00039552320558968075,0.00039550132858928375,0.0003954793985676015,0.000395457415527574,0.0003954353794721482,0.0003954132904042783,0.00039539114832692565,0.00039536895324305865,0.00039534670515565265,0.0003953244040676904,0.0003953020499821615,0.0003952796429020629,0.0003952571828303984,0.00039523466977017905,0.00039521210372442286,0.0003951894846961553,0.0003951668126884085,0.0003951440877042219,0.0003951213097466422,0.0003950984788187228,0.0003950755949235246,0.0003950526580641154,0.00039502966824357015,0.0003950066254649709,0.00039498352973140664,0.0003949603810459738,0.00039493717941177563,0.00039491392483192257,0.0003948906173095321,0.000394867256847729,0.0003948438434496448,0.0003948203771184184,0.00039479685785719575,0.00039477328566912985,0.0003947496605573809,0.0003947259825251159,0.0003947022515755093,0.0003946784677117425,0.0003946546309370039,0.00039463074125448914,0.00039460679866740086,0.00039458280317894884,0.00039455875479234997,0.0003945346535108282,0.0003945104993376145,0.000394486292275947,0.00039446203232907105,0.0003944377195002388,0.0003944133537927098,0.0003943889352097505,0.0003943644637546343,0.0003943399394306421,0.00039431536224106165,0.0003942907321891876,0.00039426604927832203,0.0003942413135117739,0.00039421652489285934,0.0003941916834249015,0.0003941667891112307,0.00039414184195518426,0.0003941168419601066,0.0003940917891293493,0.0003940666834662709,0.0003940415249742371,0.00039401631365662077,0.00039399104951680163,0.0003939657325581667,0.00039394036278410995,0.00039391494019803253,0.0003938894648033426,0.0003938639366034553,0.00039383835560179316,0.00039381272180178545,0.0003937870352068687,0.0003937612958204865,0.00039373550364608944,0.00039370965868713533,0.00039368376094708896,0.00039365781042942214,0.0003936318071376138,0.0003936057510751501,0.00039357964224552404,0.00039355348065223583,0.00039352726629879266,0.00039350099918870885,0.00039347467932550594,0.00039344830671271227,0.00039342188135386334,0.00039339540325250186,0.0003933688724121775,0.0003933422888364469,0.000393315652528874,0.00039328896349302966,0.00039326222173249187,0.0003932354272508455,0.0003932085800516828,0.000393181680138603,0.0003931547275152121,0.0003931277221851235,0.00039310066415195757,0.0003930735534193418,0.0003930463899909106,0.00039301917387030545,0.0003929919050611751,0.00039296458356717526,0.00039293720939196855,0.00039290978253922487,0.000392882303012621,0.000392854770815841,0.0003928271859525757,0.0003927995484265233,0.00039277185824138886,0.00039274411540088453,0.0003927163199087296,0.0003926884717686503,0.0003926605709843799,0.00039263261755965903,0.000392604611498235,0.0003925765528038623,0.0003925484414803026,0.0003925202775313245,0.0003924920609607037,0.0003924637917722229,0.0003924354699696719,0.00039240709555684754,0.0003923786685375538,0.0003923501889156015,0.0003923216566948088,0.00039229307187900063,0.0003922644344720092,0.0003922357444776735,0.00039220700189984,0.00039217820674236165,0.000392149359009099,0.00039212045870391934,0.000392091505830697,0.0003920625003933135,0.0003920334423956573,0.000392004331841624,0.00039197516873511613,0.0003919459530800433,0.00039191668488032234,0.0003918873641398768,0.0003918579908626375,0.0003918285650525423,0.00039179908671353595,0.0003917695558495704,0.0003917399724646047,0.00039171033656260464,0.00039168064814754333,0.0003916509072234008,0.0003916211137941642,0.0003915912678638276,0.0003915613694363922,0.0003915314185158662,0.00039150141510626484,0.0003914713592116105,0.0003914412508359324,0.0003914110899832669,0.0003913808766576574,0.00039135061086315444,0.0003913202926038153,0.0003912899218837046,0.00039125949870689384,0.00039122902307746154,0.0003911984949994933,0.00039116791447708183,0.00039113728151432667,0.00039110659611533456,0.0003910758582842192,0.0003910450680251014,0.00039101422534210876,0.0003909833302393763,0.0003909523827210457,0.00039092138279126583,0.0003908903304541926,0.0003908592257139889,0.0003908280685748247,0.0003907968590408769,0.00039076559711632953,0.0003907342828053735,0.000390702916112207,0.00039067149704103494,0.00039064002559606947,0.00039060850178152955,0.00039057692560164146,0.0003905452970606383,0.0003905136161627601,0.00039048188291225414,0.0003904500973133746,0.00039041825937038266,0.0003903863690875466,0.0003903544264691415,0.00039032243151944986,0.0003902903842427608,0.0003902582846433706,0.0003902261327255826,0.0003901939284937072,0.00039016167195206157,0.0003901293631049702,0.00039009700195676434,0.00039006458851178235,0.00039003212277436967,0.0003899996047488787,0.0003899670344396688,0.00038993441185110637,0.0003899017369875649,0.00038986900985342465,0.0003898362304530732,0.0003898033987909049,0.00038977051487132125,0.0003897375786987307,0.0003897045902775487,0.0003896715496121977,0.0003896384567071071,0.0003896053115667135,0.00038957211419546025,0.0003895388645977979,0.0003895055627781838,0.0003894722087410826,0.0003894388024909657,0.0003894053440323115,0.00038937183336960554,0.00038933827050734036,0.00038930465545001527,0.00038927098820213687,0.0003892372687682186,0.00038920349715278077,0.00038916967336035107,0.0003891357973954638,0.0003891018692626605,0.00038906788896648944,0.00038903385651150625,0.0003889997719022732,0.00038896563514335985,0.0003889314462393425,0.0003888972051948045,0.00038886291201433636,0.00038882856670253546,0.000388794169264006,0.00038875971970335954,0.00038872521802521434,0.00038869066423419566,0.00038865605833493587,0.00038862140033207426,0.0003885866902302572,0.00038855192803413776,0.00038851711374837645,0.00038848224737764023,0.0003884473289266036,0.00038841235839994756,0.00038837733580236034,0.00038834226113853713,0.0003883071344131801,0.00038827195563099825,0.0003882367247967078,0.0003882014419150318,0.0003881661069907003,0.00038813072002845037,0.00038809528103302593,0.00038805979000917804,0.0003880242469616646,0.00038798865189525064,0.000387953004814708,0.0003879173057248156,0.0003878815546303592,0.0003878457515361317,0.00038780989644693293,0.0003877739893675696,0.0003877380303028555,0.00038770201925761126,0.0003876659562366646,0.00038762984124485016,0.00038759367428700957,0.0003875574553679914,0.00038752118449265113,0.00038748486166585136,0.0003874484868924615,0.000387412060177358,0.0003873755815254243,0.0003873390509415507,0.0003873024684306346,0.00038726583399758017,0.0003872291476472988,0.0003871924093847086,0.00038715561921473475,0.00038711877714230937,0.0003870818831723716,0.0003870449373098675,0.0003870079395597499,0.00038697088992697894,0.0003869337884165214,0.0003868966350333512,0.0003868594297824492,0.0003868221726688031,0.00038678486369740764,0.00038674750287326446,0.0003867100902013823,0.00038667262568677665,0.0003866351093344701,0.00038659754114949205,0.00038655992113687893,0.0003865222493016742,0.0003864845256489281,0.000386446750183698,0.000386408922911048,0.0003863710438360493,0.00038633311296378003,0.00038629513029932524,0.0003862570958477768,0.00038621900961423387,0.0003861808716038021,0.00038614268182159454,0.0003861044402727307,0.0003860661469623375,0.00038602780189554844,0.0003859894050775041,0.000385950956513352,0.0003859124562082467,0.00038587390416734945,0.00038583530039582866,0.00038579664489885957,0.0003857579376816243,0.0003857191787493121,0.0003856803681071189,0.0003856415057602478,0.00038560259171390875,0.00038556362597331844,0.00038552460854370077,0.00038548553943028644,0.0003854464186383131,0.00038540724617302526,0.00038536802203967453,0.00038532874624351923,0.0003852894187898248,0.0003852500396838634,0.00038521060893091435,0.0003851711265362637,0.0003851315925052045,0.0003850920068430368,0.00038505236955506736,0.00038501268064661004,0.00038497294012298567,0.00038493314798952185,0.00038489330425155307,0.0003848534089144209,0.0003848134619834737,0.0003847734634640668,0.0003847334133615625,0.0003846933116813299,0.0003846531584287451,0.0003846129536091911,0.0003845726972280577,0.0003845323892907418,0.0003844920298026471,0.00038445161876918423,0.0003844111561957707,0.000384370642087831,0.0003843300764507965,0.00038428945929010547,0.000384248790611203,0.0003842080704195412,0.0003841672987205791,0.0003841264755197827,0.00038408560082262456,0.0003840446746345846,0.0003840036969611492,0.0003839626678078121,0.00038392158718007356,0.0003838804550834409,0.00038383927152342844,0.0003837980365055571,0.000383756750035355,0.0003837154121183571,0.0003836740227601051,0.0003836325819661477,0.00038359108974204053,0.0003835495460933461,0.00038350795102563373,0.00038346630454447975,0.0003834246066554673,0.0003833828573641864,0.0003833410566762341,0.00038329920459721415,0.00038325730113273726,0.0003832153462884211,0.00038317334006989027,0.00038313128248277604,0.00038308917353271666,0.0003830470132253574,0.00038300480156635024,0.0003829625385613542,0.0003829202242160349,0.0003828778585360653,0.0003828354415271248,0.0003827929731949,0.00038275045354508415,0.00038270788258337746,0.0003826652603154871,0.00038262258674712706,0.00038257986188401806,0.000382537085731888,0.0003824942582964715,0.0003824513795835099,0.00038240844959875166,0.00038236546834795196,0.000382322435836873,0.00038227935207128366,0.0003822362170569598,0.0003821930307996843,0.00038214979330524645,0.000382106504579443,0.00038206316462807715,0.00038201977345695906,0.00038197633107190586,0.00038193283747874144,0.00038188929268329665,0.00038184569669140906,0.00038180204950892326,0.00038175835114169065,0.0003817146015955694,0.0003816708008764246,0.0003816269489901283,0.0003815830459425593,0.00038153909173960324,0.0003814950863871527,0.00038145102989110716,0.0003814069222573727,0.00038136276349186256,0.00038131855360049667,0.00038127429258920186,0.00038122998046391174,0.000381185617230567,0.0003811412028951148,0.0003810967374635095,0.00038105222094171224,0.0003810076533356907,0.00038096303465142,0.00038091836489488146,0.0003808736440720637,0.000380828872188962,0.0003807840492515785,0.0003807391752659223,0.00038069425023800913,0.0003806492741738617,0.0003806042470795097,0.0003805591689609893,0.00038051403982434384,0.0003804688596756233,0.0003804236285208846,0.0003803783463661915,0.0003803330132176145,0.0003802876290812311,0.0003802421939631255,0.0003801967078693888,0.00038015117080611883,0.00038010558277942036,0.0003800599437954051,0.00038001425386019125,0.0003799685129799041,0.0003799227211606758,0.0003798768784086452,0.00037983098472995806,0.00037978504013076687,0.000379739044617231,0.0003796929981955167,0.00037964690087179695,0.0003796007526522516,0.0003795545535430675,0.00037950830355043785,0.0003794620026805632,0.00037941565093965057,0.000379369248333914,0.00037932279486957416,0.00037927629055285874,0.0003792297353900022,0.00037918312938724555,0.0003791364725508371,0.00037908976488703147,0.00037904300640209047,0.00037899619710228267,0.0003789493369938832,0.00037890242608317425,0.00037885546437644473,0.00037880845187999036,0.0003787613886001137,0.00037871427454312407,0.0003786671097153377,0.0003786198941230774,0.0003785726277726731,0.0003785253106704613,0.0003784779428227854,0.0003784305242359955,0.0003783830549164487,0.0003783355348705087,0.00037828796410454613,0.0003782403426249383,0.0003781926704380695,0.0003781449475503306,0.00037809717396811946,0.00037804934969784055,0.00037800147474590534,0.000377953549118732,0.0003779055728227454,0.00037785754586437735,0.0003778094682500663,0.00037776133998625774,0.0003777131610794036,0.000377664931535963,0.00037761665136240146,0.0003775683205651916,0.00037751993915081255,0.00037747150712575046,0.0003774230244964982,0.00037737449126955535,0.00037732590745142826,0.00037727727304863023,0.00037722858806768126,0.000377179852515108,0.00037713106639744397,0.00037708222972122955,0.00037703334249301185,0.00037698440471934476,0.00037693541640678883,0.0003768863775619115,0.000376837288191287,0.00037678814830149627,0.0003767389578991271,0.0003766897169907739,0.00037664042558303813,0.00037659108368252766,0.0003765416912958574,0.0003764922484296489,0.0003764427550905306,0.00037639321128513754,0.00037634361702011167,0.00037629397230210155,0.0003762442771377627,0.00037619453153375727,0.0003761447354967541,0.0003760948890334291,0.0003760449921504646,0.0003759950448545499,0.00037594504715238083,0.0003758949990506603,0.00037584490055609765,0.0003757947516754093,0.0003757445524153181,0.00037569430278255395,0.0003756440027838533,0.00037559365242595936,0.00037554325171562224,0.0003754928006595987,0.00037544229926465215,0.00037539174753755295,0.00037534114548507815,0.0003752904931140114,0.00037523979043114326,0.00037518903744327103,0.0003751382341571986,0.0003750873805797368,0.00037503647671770305,0.00037498552257792157,0.0003749345181672233,0.0003748834634924461,0.0003748323585604342,0.0003747812033780389,0.000374729997952118,0.0003746787422895363,0.00037462743639716503,0.0003745760802818825,0.00037452467395057335,0.00037447321741012924,0.00037442171066744855,0.0003743701537294363,0.0003743185466030042,0.0003742668892950708,0.0003742151818125613,0.0003741634241624076,0.00037411161635154857,0.0003740597583869294,0.00037400785027550234,0.00037395589202422617,0.0003739038836400666,0.00037385182512999577,0.0003737997165009927,0.00037374755776004324,0.0003736953489141398,0.0003736430899702814,0.00037359078093547414,0.0003735384218167305,0.0003734860126210698,0.00037343355335551815,0.0003733810440271081,0.00037332848464287935,0.00037327587520987783,0.0003732232157351566,0.0003731705062257751,0.0003731177466887997,0.0003730649371313034,0.0003730120775603658,0.0003729591679830734,0.00037290620840651925,0.00037285319883780324,0.00037280013928403175,0.00037274702975231816,0.0003726938702497823,0.00037264066078355074,0.0003725874013607568,0.00037253409198854064,0.0003724807326740488,0.0003724273234244347,0.0003723738642468585,0.00037232035514848694,0.00037226679613649354,0.0003722131872180584,0.0003721595284003685,0.00037210581969061726,0.000372052061096005,0.00037199825262373867,0.0003719443942810318,0.00037189048607510475,0.0003718365280131845,0.00037178252010250476,0.00037172846235030576,0.00037167435476383463,0.0003716201973503451,0.00037156599011709744,0.00037151173307135887,0.00037145742622040316,0.0003714030695715105,0.0003713486631319683,0.0003712942069090701,0.0003712397009101165,0.0003711851451424146,0.00037113053961327806,0.0003710758843300275,0.0003710211792999901,0.00037096642453049954,0.00037091162002889636,0.00037085676580252765,0.0003708018618587473,0.0003707469082049157,0.00037069190484840007,0.00037063685179657417,0.00037058174905681845,0.00037052659663652007,0.00037047139454307284,0.00037041614278387715,0.0003703608413663401,0.0003703054902978755,0.0003702500895859037,0.00037019463923785185,0.0003701391392611536,0.0003700835896632494,0.0003700279904515862,0.00036997234163361776,0.0003699166432168044,0.0003698608952086131,0.0003698050976165174,0.0003697492504479978,0.00036969335371054104,0.00036963740741164064,0.000369581411558797,0.0003695253661595169,0.00036946927122131373,0.0003694131267517078,0.00036935693275822574,0.0003693006892484011,0.00036924439622977394,0.00036918805370989087,0.0003691316616963052,0.00036907522019657697,0.0003690187292182728,0.00036896218876896587,0.0003689055988562361,0.0003688489594876699,0.0003687922706708604,0.0003687355324134075,0.00036867874472291744,0.0003686219076070033,0.00036856502107328467,0.0003685080851293879,0.0003684510997829458,0.0003683940650415979,0.0003683369809129903,0.0003682798474047758,0.00036822266452461375,0.0003681654322801702,0.00036810815067911764,0.0003680508197291354,0.0003679934394379093,0.0003679360098131317,0.0003678785308625019,0.00036782100259372537,0.0003677634250145144,0.00036770579813258803,0.0003676481219556717,0.0003675903964914975,0.00036753262174780423,0.0003674747977323373,0.00036741692445284844,0.0003673590019170963,0.0003673010301328461,0.0003672430091078695,0.0003671849388499449,0.00036712681936685725,0.0003670686506663981,0.0003670104327563656,0.00036695216564456445,0.0003668938493388061,0.0003668354838469084,0.00036677706917669594,0.00036671860533599973,0.0003666600923326577,0.000366601530174514,0.0003665429188694195,0.00036648425842523177,0.00036642554884981496,0.00036636679015103956,0.0003663079823367829,0.00036624912541492885,0.00036619021939336775,0.00036613126427999666,0.0003660722600827191,0.00036601320680944527,0.0003659541044680919,0.00036589495306658227,0.00036583575261284635,0.00036577650311482053,0.0003657172045804479,0.0003656578570176781,0.00036559846043446726,0.00036553901483877817,0.0003654795202385802,0.00036541997664184917,0.00036536038405656765,0.00036530074249072455,0.0003652410519523156,0.00036518131244934294,0.0003651215239898153,0.0003650616865817479,0.00036500180023316266,0.00036494186495208806,0.000364881880746559,0.0003648218476246171,0.0003647617655943104,0.0003647016346636935,0.00036464145484082773,0.00036458122613378075,0.0003645209485506269,0.00036446062209944714,0.0003644002467883288,0.00036433982262536587,0.00036427934961865885,0.00036421882777631486,0.0003641582571064475,0.0003640976376171769,0.0003640369693166298,0.00036397625221293946,0.00036391548631424563,0.00036385467162869465,0.00036379380816443945,0.00036373289592963936,0.0003636719349324604,0.0003636109251810751,0.00036354986668366235,0.00036348875944840783,0.00036342760348350356,0.00036336639879714814,0.00036330514539754683,0.0003632438432929113,0.00036318249249145976,0.0003631210930014169,0.000363059644831014,0.00036299814798848893,0.000362936602482086,0.000362875008320056,0.0003628133655106563,0.00036275167406215085,0.0003626899339828101,0.00036262814528091093,0.00036256630796473676,0.0003625044220425776,0.00036244248752272996,0.0003623805044134968,0.0003623184727231876,0.0003622563924601185,0.00036219426363261187,0.0003621320862489969,0.00036206986031760916,0.00036200758584679064,0.00036194526284488997,0.0003618828913202621,0.00036182047128126884,0.0003617580027362781,0.0003616954856936646,0.0003616329201618093,0.00036157030614909986,0.00036150764366393043,0.0003614449327147015,0.0003613821733098202,0.00036131936545770015,0.0003612565091667614,0.00036119360444543055,0.00036113065130214056,0.0003610676497453312,0.00036100459978344833,0.0003609415014249446,0.0003608783546782789,0.0003608151595519169,0.00036075191605433046,0.0003606886241939982,0.000360625283979405,0.0003605618954190423,0.0003604984585214081,0.00036043497329500674,0.0003603714397483492,0.0003603078578899527,0.00036024422772834125,0.00036018054927204504,0.00036011682252960097,0.00036005304750955216,0.00035998922422044854,0.0003599253526708462,0.0003598614328693079,0.0003597974648244026,0.0003597334485447062,0.00035966938403880056,0.0003596052713152744,0.0003595411103827225,0.00035947690124974656,0.0003594126439249544,0.00035934833841696047,0.0003592839847343856,0.0003592195828858572,0.00035915513288000886,0.0003590906347254809,0.00035902608843092006,0.0003589614940049794,0.0003588968514563185,0.00035883216079360354,0.0003587674220255069,0.0003587026351607075,0.00035863780020789076,0.0003585729171757485,0.00035850798607297906,0.00035844300690828716,0.00035837797969038383,0.0003583129044279869,0.0003582477811298202,0.0003581826098046144,0.00035811739046110635,0.0003580521231080394,0.0003579868077541634,0.0003579214444082346,0.0003578560330790156,0.0003577905737752755,0.00035772506650578995,0.00035765951127934083,0.00035759390810471655,0.00035752825699071194,0.0003574625579461283,0.0003573968109797732,0.0003573310161004608,0.0003572651733170116,0.00035719928263825264,0.00035713334407301724,0.0003570673576301451,0.00035700132331848247,0.00035693524114688204,0.0003568691111242028,0.00035680293325931014,0.00035673670756107605,0.0003566704340383787,0.00035660411270010294,0.0003565377435551397,0.0003564713266123865,0.0003564048618807474,0.0003563383493691326,0.00035627178908645884,0.0003562051810416494,0.0003561385252436336,0.00035607182170134755,0.00035600507042373347,0.0003559382714197402,0.0003558714246983228,0.0003558045302684428,0.0003557375881390683,0.00035567059831917333,0.0003556035608177389,0.0003555364756437519,0.0003554693428062061,0.000355402162314101,0.00035533493417644324,0.0003552676584022453,0.0003552003350005263,0.0003551329639803116,0.0003550655453506332,0.0003549980791205291,0.00035493056529904406,0.00035486300389522894,0.0003547953949181411,0.00035472773837684425,0.00035466003428040856,0.0003545922826379104,0.00035452448345843273,0.0003544566367510647,0.00035438874252490194,0.00035432080078904644,0.00035425281155260647,0.00035418477482469676,0.0003541166906144384,0.0003540485589309588,0.0003539803797833917,0.0003539121531808774,0.0003538438791325623,0.0003537755576475993,0.00035370718873514777,0.00035363877240437313,0.00035357030866444745,0.000353501797524549,0.0003534332389938625,0.00035336463308157897,0.0003532959797968957,0.0003532272791490165,0.0003531585311471514,0.00035308973580051677,0.00035302089311833553,0.0003529520031098367,0.0003528830657842557,0.00035281408115083444,0.000352745049218821,0.0003526759699974698,0.00035260684349604183,0.0003525376697238041,0.00035246844869003027,0.000352399180404,0.0003523298648749996,0.0003522605021123215,0.0003521910921252646,0.00035212163492313403,0.00035205213051524124,0.00035198257891090416,0.0003519129801194469,0.00035184333415019987,0.00035177364101249996,0.0003517039007156903,0.00035163411326912035,0.0003515642786821458,0.00035149439696412877,0.00035142446812443773,0.00035135449217244734,0.0003512844691175387,0.0003512143989690991,0.0003511442817365223,0.00035107411742920817,0.0003510039060565631,0.00035093364762799967,0.00035086334215293677,0.00035079298964079965,0.0003507225901010198,0.000350652143543035,0.0003505816499762895,0.0003505111094102337,0.0003504405218543243,0.00035036988731802435,0.00035029920581080323,0.0003502284773421364,0.00035015770192150603,0.00035008687955840023,0.0003500160102623135,0.00034994509404274657,0.00034987413090920667,0.0003498031208712071,0.0003497320639382676,0.00034966096011991414,0.0003495898094256788,0.00034951861186510036,0.0003494473674477234,0.0003493760761830992,0.00034930473808078506,0.0003492333531503446,0.00034916192140134776,0.00034909044284337073,0.0003490189174859961,0.00034894734533881256,0.00034887572641141513,0.0003488040607134051,0.0003487323482543901,0.0003486605890439839,0.00034858878309180667,0.0003485169304074847,0.00034844503100065074,0.0003483730848809436,0.00034830109205800854,0.0003482290525414969,0.0003481569663410664,0.00034808483346638095,0.00034801265392711084,0.0003479404277329325,0.00034786815489352854,0.000347795835418588,0.00034772346931780617,0.0003476510566008844,0.0003475785972775304,0.00034750609135745825,0.00034743353885038805,0.0003473609397660464,0.00034728829411416587,0.00034721560190448546,0.00034714286314675035,0.00034707007785071193,0.00034699724602612795,0.0003469243676827622,0.00034685144283038495,0.0003467784714787724,0.0003467054536377074,0.0003466323893169786,0.0003465592785263811,0.0003464861212757163,0.00034641291757479164,0.0003463396674334209,0.00034626637086142406,0.00034619302786862734,0.00034611963846486316,0.0003460462026599702,0.0003459727204637933,0.0003458991918861836,0.0003458256169369983,0.00034575199562610103,0.0003456783279633616,0.0003456046139586558,0.0003455308536218659,0.0003454570469628802,0.0003453831939915934,0.00034530929471790624,0.0003452353491517257,0.0003451613573029651,0.00034508731918154377,0.0003450132347973873,0.0003449391041604276,0.00034486492728060263,0.00034479070416785666,0.0003447164348321401,0.0003446421192834095,0.0003445677575316278,0.0003444933495867639,0.0003444188954587931,0.00034434439515769667,0.00034426984869346226,0.00034419525607608356,0.0003441206173155607,0.00034404593242189974,0.0003439712014051129,0.0003438964242752188,0.00034382160104224214,0.0003437467317162138,0.0003436718163071707,0.0003435968548251563,0.0003435218472802198,0.0003434467936824169,0.0003433716940418093,0.000343296548368465,0.00034322135667245795,0.00034314611896386855,0.00034307083525278323,0.0003429955055492946,0.0003429201298635014,0.00034284470820550853,0.0003427692405854272,0.00034269372701337456,0.0003426181674994741,0.0003425425620538554,0.0003424669106866541,0.0003423912134080122,0.0003423154702280777,0.00034223968115700487,0.00034216384620495396,0.00034208796538209163,0.0003420120386985904,0.00034193606616462905,0.00034186004779039267,0.0003417839835860722,0.000341707873561865,0.00034163171772797445,0.0003415555160946099,0.0003414792686719873,0.0003414029754703282,0.00034132663649986066,0.0003412502517708188,0.0003411738212934427,0.0003410973450779788,0.0003410208231346795,0.00034094425547380344,0.00034086764210561544,0.00034079098304038623,0.00034071427828839286,0.0003406375278599184,0.00034056073176525213,0.0003404838900146894,0.0003404070026185317,0.0003403300695870866,0.0003402530909306678,0.00034017606665959514,0.0003400989967841946,0.00034002188131479824,0.0003399447202617442,0.00033986751363537684,0.0003397902614460465,0.00033971296370410956,0.00033963562041992883,0.00033955823160387297,0.00033948079726631674,0.00033940331741764106,0.000339325792068233,0.00033924822122848573,0.0003391706049087983,0.00033909294311957624,0.0003390152358712308,0.0003389374831741796,0.00033885968503884607,0.00033878184147566017,0.0003387039524950574,0.00033862601810747984,0.0003385480383233754,0.00033847001315319804,0.00033839194260740793,0.0003383138266964713,0.00033823566543086047,0.0003381574588210538,0.0003380792068775357,0.0003380009096107967,0.00033792256703133345,0.00033784417914964863,0.00033776574597625095,0.00033768726752165525,0.00033760874379638254,0.0003375301748109596,0.00033745156057591956,0.00033737290110180153,0.0003372941963991506,0.00033721544647851814,0.00033713665135046123,0.0003370578110255434,0.00033697892551433405,0.00033689999482740854,0.0003368210189753485,0.0003367419979687414,0.00033666293181818093,0.0003365838205342668,0.00033650466412760464,0.0003364254626088064,0.00033634621598848974,0.0003362669242772787,0.0003361875874858031,0.00033610820562469886,0.00033602877870460816,0.0003359493067361788,0.0003358697897300652,0.00033579022769692716,0.000335710620647431,0.0003356309685922489,0.0003355512715420591,0.00033547152950754583,0.0003353917424993994,0.00033531191052831613,0.00033523203360499843,0.00033515211174015453,0.000335072144944499,0.00033499213322875213,0.00033491207660364046,0.0003348319750798964,0.0003347518286682585,0.0003346716373794712,0.000334591401224285,0.00033451112021345655,0.0003344307943577483,0.0003343504236679288,0.00033427000815477266,0.0003341895478290605,0.00033410904270157884,0.0003340284927831203,0.0003339478980844835,0.000333867258616473,0.0003337865743898995,0.00033370584541557945,0.00033362507170433555,0.00033354425326699637,0.00033346339011439656,0.0003333824822573766,0.00033330152970678325,0.000333220532473469,0.0003331394905682923,0.0003330584040021179,0.00033297727278581616,0.00033289609693026373,0.00033281487644634303,0.0003327336113449427,0.0003326523016369572,0.00033257094733328676,0.00033248954844483804,0.0003324081049825234,0.00033232661695726113,0.00033224508437997577,0.0003321635072615976,0.0003320818856130628,0.00033200021944531375,0.00033191850876929867,0.00033183675359597177,0.00033175495393629326,0.0003316731098012293,0.0003315912212017519,0.00033150928814883917,0.00033142731065347514,0.0003313452887266498,0.00033126322237935906,0.0003311811116226049,0.00033109895646739497,0.00033101675692474326,0.0003309345130056694,0.00033085222472119925,0.0003307698920823643,0.00033068751510020216,0.0003306050937857564,0.0003305226281500765,0.0003304401182042179,0.00033035756395924186,0.00033027496542621583,0.00033019232261621297,0.00033010963554031247,0.0003300269042095994,0.00032994412863516484,0.00032986130882810575,0.00032977844479952504,0.00032969553656053154,0.00032961258412224,0.0003295295874957711,0.0003294465466922515,0.0003293634617228136,0.000329280332598596,0.00032919715933074303,0.0003291139419304049,0.00032903068040873783,0.000328947374776904,0.00032886402504607145,0.00032878063122741407,0.00032869719333211174,0.0003286137113713502,0.00032853018535632117,0.00032844661529822213,0.0003283630012082567,0.0003282793430976342,0.00032819564097756983,0.00032811189485928494,0.00032802810475400653,0.00032794427067296754,0.00032786039262740685,0.0003277764706285694,0.0003276925046877056,0.0003276084948160722,0.0003275244410249315,0.00032744034332555193,0.0003273562017292077,0.00032727201624717893,0.0003271877868907515,0.00032710351367121735,0.00032701919659987425,0.0003269348356880258,0.0003268504309469815,0.0003267659823880567,0.00032668149002257276,0.0003265969538618567,0.00032651237391724156,0.0003264277502000662,0.00032634308272167536,0.00032625837149341964,0.0003261736165266555,0.0003260888178327453,0.0003260039754230572,0.00032591908930896526,0.00032583415950184944,0.00032574918601309546,0.00032566416885409496,0.0003255791080362454,0.0003254940035709502,0.00032540885546961844,0.0003253236637436652,0.00032523842840451135,0.00032515314946358366,0.0003250678269323147,0.0003249824608221428,0.00032489705114451233,0.00032481159791087336,0.0003247261011326818,0.00032464056082139953,0.000324554976988494,0.00032446934964543877,0.0003243836788037132,0.0003242979644748022,0.00032421220667019684,0.00032412640540139387,0.00032404056067989595,0.00032395467251721146,0.0003238687409248546,0.0003237827659143455,0.00032369674749721,0.0003236106856849799,0.00032352458048919263,0.0003234384319213916,0.00032335223999312596,0.00032326600471595067,0.00032317972610142653,0.0003230934041611201,0.00032300703890660373,0.0003229206303494558,0.00032283417850126014,0.00032274768337360674,0.0003226611449780911,0.0003225745633263146,0.00032248793842988457,0.00032240127030041393,0.00032231455894952163,0.0003222278043888322,0.000322141006629976,0.00032205416568458926,0.0003219672815643139,0.00032188035428079776,0.00032179338384569434,0.0003217063702706631,0.00032161931356736905,0.00032153221374748306,0.00032144507082268193,0.00032135788480464804,0.0003212706557050697,0.0003211833835356408,0.0003210960683080613,0.0003210087100340366,0.0003209213087252782,0.0003208338643935031,0.0003207463770504342,0.00032065884670780004,0.00032057127337733516,0.00032048365707077966,0.00032039599779987946,0.0003203082955763863,0.0003202205504120575,0.00032013276231865643,0.0003200449313079519,0.0003199570573917187,0.00031986914058173725,0.0003197811808897938,0.0003196931783276803,0.0003196051329071944,0.00031951704464013963,0.0003194289135383252,0.0003193407396135659,0.0003192525228776826,0.00031916426334250165,0.00031907596101985516,0.00031898761592158106,0.00031889922805952296,0.00031881079744553023,0.000318722324091458,0.0003186338080091671,0.00031854524921052396,0.00031845664770740095,0.0003183680035116761,0.0003182793166352331,0.0003181905870899614,0.0003181018148877561,0.00031801300004051817,0.00031792414256015425,0.0003178352424585765,0.00031774629974770316,0.0003176573144394578,0.00031756828654577,0.00031747921607857475,0.0003173901030498131,0.0003173009474714316,0.00031721174935538246,0.0003171225087136237,0.00031703322555811904,0.0003169438999008378,0.0003168545317537551,0.00031676512112885173,0.0003166756680381141,0.0003165861724935345,0.00031649663450711063,0.00031640705409084616,0.00031631743125675035,0.000316227766016838,0.0003161380583831297,0.0003160483083676519,0.0003159585159824365,0.00031586868123952114,0.00031577880415094913,0.00031568888472876947,0.0003155989229850369,0.00031550891893181176,0.00031541887258116014,0.00031532878394515356,0.00031523865303586954,0.0003151484798653911,0.0003150582644458069,0.0003149680067892113,0.0003148777069077044,0.0003147873648133918,0.0003146969805183849,0.00031460655403480067,0.00031451608537476177,0.0003144255745503966,0.000314335021573839,0.0003142444264572287,0.00031415378921271093,0.0003140631098524365,0.0003139723883885622,0.00031388162483325,0.00031379081919866793,0.0003136999714969893,0.0003136090817403934,0.000313518149941065,0.0003134271761111943,0.00031333616026297753,0.00031324510240861634,0.00031315400256031806,0.00031306286073029543,0.00031297167693076724,0.0003128804511739576,0.00031278918347209624,0.0003126978738374187,0.00031260652228216597,0.0003125151288185848,0.00031242369345892737,0.0003123322162154517,0.0003122406971004213,0.00031214913612610524,0.0003120575333047784,0.000311965888648721,0.00031187420217021906,0.0003117824738815642,0.00031169070379505353,0.0003115988919229899,0.0003115070382776817,0.0003114151428714428,0.00031132320571659297,0.00031123122682545726,0.0003111392062103664,0.000311047143883657,0.0003109550398576708,0.00031086289414475544,0.000310770706757264,0.00031067847770755526,0.0003105862070079936,0.00031049389467094877,0.00031040154070879634,0.0003103091451339174,0.0003102167079586985,0.0003101242291955319,0.0003100317088568154,0.0003099391469549524,0.00030984654350235175,0.00030975389851142803,0.0003096612119946012,0.0003095684839642971,0.0003094757144329468,0.0003093829034129871,0.00030929005091686034,0.0003091971569570144,0.0003091042215459027,0.0003090112446959843,0.00030891822641972383,0.00030882516672959127,0.0003087320656380624,0.00030863892315761835,0.00030854573930074597,0.0003084525140799375,0.0003083592475076909,0.0003082659395965095,0.00030817259035890223,0.00030807919980738364,0.00030798576795447376,0.00030789229481269817,0.00030779878039458784,0.0003077052247126795,0.00030761162777951534,0.00030751798960764295,0.0003074243102096157,0.00030733058959799215,0.00030723682778533676,0.00030714302478421923,0.0003070491806072149,0.00030695529526690465,0.0003068613687758747,0.0003067674011467171,0.0003066733923920291,0.00030657934252441375,0.0003064852515564793,0.0003063911195008398,0.0003062969463701146,0.0003062027321769287,0.00030610847693391253,0.0003060141806537021,0.0003059198433489387,0.0003058254650322694,0.0003057310457163466,0.0003056365854138283,0.0003055420841373778,0.0003054475418996642,0.00030535295871336184,0.0003052583345911507,0.000305163669545716,0.0003050689635897488,0.0003049742167359455,0.0003048794289970078,0.00030478460038564317,0.0003046897309145643,0.00030459482059648957,0.00030449986944414267,0.00030440487747025296,0.00030430984468755504,0.0003042147711087892,0.000304119656746701,0.00030402450161404166,0.00030392930572356765,0.0003038340690880411,0.0003037387917202295,0.0003036434736329058,0.0003035481148388485,0.00030345271535084145,0.000303357275181674,0.00030326179434414096,0.0003031662728510426,0.0003030707107151845,0.000302975107949378,0.0003028794645664396,0.0003027837805791913,0.00030268805600046063,0.00030259229084308054,0.0003024964851198894,0.00030240063884373093,0.00030230475202745456,0.00030220882468391474,0.00030211285682597177,0.0003020168484664911,0.00030192079961834366,0.00030182471029440594,0.00030172858050755974,0.00030163241027069223,0.00030153619959669625,0.00030143994849846973,0.0003013436569889163,0.00030124732508094484,0.0003011509527874697,0.00030105454012141063,0.00030095808709569284,0.00030086159372324687,0.0003007650600170088,0.0003006684859899199,0.0003005718716549271,0.0003004752170249825,0.0003003785221130438,0.00030028178693207393,0.00030018501149504137,0.00030008819581491995,0.0002999913399046888,0.0002998944437773325,0.0002997975074458412,0.00029970053092321004,0.00029960351422244,0.00029950645735653703,0.0002994093603385128,0.00029931222318138427,0.0002992150458981736,0.0002991178285019086,0.0002990205710056222,0.0002989232734223529,0.00029882593576514453,0.00029872855804704624,0.00029863114028111257,0.0002985336824804035,0.00029843618465798423,0.00029833864682692545,0.00029824106900030317,0.00029814345119119883,0.000298045793412699,0.0002979480956778959,0.000297850357999887,0.00029775258039177515,0.00029765476286666833,0.0002975569054376802,0.00029745900811792953,0.0002973610709205406,0.0002972630938586429,0.00029716507694537136,0.00029706702019386625,0.0002969689236172731,0.0002968707872287429,0.00029677261104143175,0.0002966743950685015,0.00029657613932311885,0.00029647784381845615,0.000296379508567691,0.0002962811335840063,0.00029618271888059023,0.0002960842644706364,0.0002959857703673439,0.0002958872365839166,0.00029578866313356424,0.0002956900500295017,0.00029559139728494897,0.00029549270491313173,0.0002953939729272806,0.00029529520134063183,0.0002951963901664267,0.00029509753941791205,0.00029499864910833987,0.0002948997192509674,0.0002948007498590574,0.00029470174094587776,0.0002946026925247017,0.0002945036046088077,0.00029440447721147954,0.00029430531034600657,0.00029420610402568296,0.0002941068582638085,0.00029400757307368816,0.0002939082484686322,0.00029380888446195615,0.00029370948106698086,0.0002936100382970325,0.0002935105561654424,0.0002934110346855472,0.00029331147387068893,0.00029321187373421474,0.00029311223428947714,0.00029301255554983394,0.00029291283752864804,0.00029281308023928793,0.00029271328369512696,0.00029261344790954403,0.0002925135728959233,0.000292413658667654,0.00029231370523813074,0.00029221371262075347,0.0002921136808289272,0.0002920136098760623,0.0002919134997755743,0.0002918133505408843,0.0002917131621854182,0.0002916129347226073,0.00029151266816588835,0.00029141236252870314,0.00029131201782449866,0.0002912116340667273,0.0002911112112688466,0.0002910107494443193,0.00029091024860661334,0.0002908097087692021,0.00029070912994556396,0.00029060851214918263,0.000290507855393547,0.0002904071596921513,0.0002903064250584948,0.00029020565150608213,0.0002901048390484231,0.0002900039876990327,0.00028990309747143104,0.00028980216837914377,0.0002897012004357014,0.00028960019365463995,0.0002894991480495002,0.0002893980636338287,0.00028929694042117683,0.0002891957784251012,0.00028909457765916366,0.00028899333813693146,0.00028889205987197675,0.000288790742877877,0.0002886893871682148,0.0002885879927565781,0.0002884865596565599,0.00028838508788175835,0.0002882835774457769,0.00028818202836222424,0.000288080440644714,0.00028797881430686514,0.00028787714936230185,0.0002877754458246534,0.00028767370370755415,0.00028757192302464394,0.0002874701037895675,0.00028736824601597477,0.00028726634971752094,0.00028716441490786633,0.0002870624416006765,0.0002869604298096218,0.0002868583795483784,0.00028675629083062704,0.00028665416367005387,0.0002865519980803501,0.00028644979407521225,0.0002863475516683419,0.00028624527087344566,0.0002861429517042354,0.00028604059417442824,0.0002859381982977462,0.00028583576408791654,0.0002857332915586719,0.0002856307807237497,0.00028552823159689255,0.0002854256441918485,0.00028532301852237036,0.0002852203546022162,0.0002851176524451494,0.00028501491206493816,0.0002849121334753561,0.00028480931669018164,0.0002847064617231986,0.0002846035685881958,0.0002845006372989672,0.00028439766786931186,0.00028429466031303395,0.00028419161464394283,0.00028408853087585277,0.0002839854090225833,0.0002838822490979592,0.00028377905111581,0.0002836758150899706,0.0002835725410342809,0.000283469228962586,0.00028336587888873587,0.00028326249082658575,0.000283159064789996,0.00028305560079283214,0.0002829520988489644,0.0002828485589722684,0.00028274498117662495,0.0002826413654759197,0.00028253771188404344,0.00028243402041489197,0.00028233029108236656,0.000282226523900373,0.00028212271888282257,0.00028201887604363134,0.0002819149953967207,0.0002818110769560169,0.0002817071207354514,0.00028160312674896067,0.0002814990950104862,0.0002813950255339746,0.00028129091833337756,0.0002811867734226517,0.00028108259081575894,0.0002809783705266659,0.0002808741125693447,0.00028076981695777204,0.00028066548370593,0.0002805611128278055,0.0002804567043373907,0.0002803522582486827,0.00028024777457568356,0.0002801432533324006,0.0002800386945328458,0.0002799340981910367,0.0002798294643209954,0.00027972479293674927,0.0002796200840523306,0.00027951533768177684,0.0002794105538391304,0.00027930573253843853,0.00027920087379375394,0.0002790959776191339,0.00027899104402864095,0.0002788860730363426,0.0002787810646563113,0.0002786760189026247,0.00027857093578936517,0.0002784658153306204,0.0002783606575404828,0.0002782554624330501,0.00027815023002242473,0.0002780449603227142,0.0002779396533480312,0.0002778343091124933,0.00027772892763022283,0.00027762350891534753,0.0002775180529819999,0.0002774125598443174,0.0002773070295164426,0.000277201462012523,0.00027709585734671103,0.00027699021553316414,0.00027688453658604483,0.0002767788205195206,0.00027667306734776366,0.00027656727708495147,0.0002764614497452664,0.00027635558534289573,0.0002762496838920317,0.00027614374540687166,0.0002760377699016178,0.0002759317573904772,0.0002758257078876621,0.0002757196214073896,0.00027561349796388174,0.0002755073375713654,0.0002754011402440728,0.0002752949059962406,0.00027518863484211084,0.0002750823267959302,0.0002749759818719505,0.00027486960008442856,0.00027476318144762583,0.00027465672597580895,0.00027455023368324954,0.00027444370458422395,0.0002743371386930136,0.0002742305360239048,0.0002741238965911889,0.00027401722040916194,0.00027391050749212513,0.00027380375785438453,0.000273696971510251,0.00027359014847404045,0.00027348328876007367,0.00027337639238267646,0.0002732694593561794,0.00027316248969491794,0.0002730554834132327,0.00027294844052546893,0.00027284136104597693,0.0002727342449891119,0.00027262709236923385,0.0002725199032007079,0.00027241267749790373,0.00027230541527519637,0.0002721981165469653,0.00027209078132759513,0.00027198340963147533,0.0002718760014730003,0.0002717685568665692,0.0002716610758265863,0.00027155355836746046,0.0002714460045036056,0.0002713384142494405,0.0002712307876193889,0.00027112312462787926,0.00027101542528934497,0.00027090768961822426,0.0002707999176289604,0.00027069210933600136,0.0002705842647537999,0.000270476383896814,0.00027036846677950605,0.00027026051341634365,0.0002701525238217991,0.00027004449801034953,0.0002699364359964771,0.00026982833779466865,0.00026972020341941585,0.00026961203288521546,0.0002695038262065688,0.0002693955833979822,0.0002692873044739667,0.00026917898944903845,0.0002690706383377182,0.0002689622511545315,0.000268853827914009,0.0002687453686306859,0.0002686368733191024,0.0002685283419938035,0.00026841977466933903,0.0002683111713602635,0.0002682025320811366,0.00026809385684652235,0.00026798514567099007,0.0002678763985691136,0.0002677676155554717,0.0002676587966446479,0.00026754994185123053,0.00026744105118981285,0.00026733212467499283,0.0002672231623213732,0.00026711416414356164,0.00026700513015617046,0.000266896060373817,0.0002667869548111231,0.0002666778134827156,0.00026656863640322614,0.0002664594235872911,0.00026635017504955156,0.0002662408908046536,0.000266131570867248,0.00026602221525199015,0.0002659128239735404,0.000265803397046564,0.0002656939344857306,0.00026558443630571505,0.0002654749025211967,0.0002653653331468597,0.0002652557281973931,0.00026514608768749064,0.0002650364116318508,0.0002649267000451769,0.0002648169529421769,0.0002647071703375637,0.0002645973522460548,0.0002644874986823725,0.000264377609661244,0.00026426768519740093,0.00026415772530558,0.00026404773000052254,0.00026393769929697455,0.0002638276332096869,0.0002637175317534152,0.0002636073949429197,0.0002634972227929654,0.0002633870153183222,0.0002632767725337645,0.0002631664944540716,0.00026305618109402753,0.000262945832468421,0.00026283544859204535,0.00026272502947969885,0.0002626145751461843,0.00026250408560630947,0.0002623935608748865,0.0002622830009667326,0.0002621724058966695,0.00026206177567952355,0.00026195111033012607,0.000261840409863313,0.00026172967429392483,0.00026161890363680696,0.0002615080979068094,0.00026139725711878684,0.00026128638128759867,0.00026117547042810906,0.0002610645245551869,0.00026095354368370555,0.0002608425278285433,0.00026073147700458307,0.00026062039122671236,0.00026050927050982344,0.0002603981148688133,0.00026028692431858357,0.0002601756988740406,0.0002600644385500953,0.0002599531433616633,0.0002598418133236651,0.0002597304484510255,0.00025961904875867434,0.00025950761426154595,0.0002593961449745794,0.00025928464091271817,0.0002591731020909107,0.0002590615285241101,0.0002589499202272739,0.0002588382772153645,0.00025872659950334874,0.0002586148871061984,0.0002585031400388896,0.0002583913583164034,0.0002582795419537253,0.0002581676909658454,0.0002580558053677588,0.0002579438851744647,0.0002578319304009675,0.00025771994106227574,0.00025760791717340296,0.0002574958587493672,0.000257383765805191,0.00025727163835590166,0.0002571594764165312,0.0002570472800021161,0.0002569350491276975,0.00025682278380832123,0.0002567104840590376,0.0002565981498949017,0.0002564857813309731,0.0002563733783823161,0.00025626094106399953,0.0002561484693910968,0.00025603596337868596,0.00025592342304184973,0.00025581084839567536,0.0002556982394552547,0.0002555855962356842,0.000255472918752065,0.00025536020701950266,0.00025524746105310737,0.00025513468086799416,0.0002550218664792823,0.00025490901790209576,0.0002547961351515633,0.00025468321824281793,0.00025457026719099743,0.00025445728201124414,0.00025434426271870496,0.0002542312093285314,0.0002541181218558795,0.00025400500031590986,0.0002538918447237876,0.0002537786550946825,0.000253665431443769,0.00025355217378622574,0.00025343888213723634,0.0002533255565119887,0.00025321219692567537,0.0002530988033934935,0.0002529853759306446,0.00025287191455233496,0.0002527584192737754,0.00025264489011018104,0.00025253132707677177,0.00025241773018877203,0.0002523040994614106,0.0002521904349099211,0.0002520767365495413,0.00025196300439551386,0.00025184923846308577,0.0002517354387675086,0.00025162160532403845,0.00025150773814793594,0.0002513938372544662,0.0002512799026588989,0.0002511659343765082,0.0002510519324225729,0.00025093789681237606,0.00025082382756120544,0.00025070972468435343,0.00025059558819711655,0.0002504814181147962,0.00025036721445269804,0.00025025297722613233,0.0002501387064504139,0.0002500244021408619,0.00024991006431280015,0.0002497956929815568,0.0002496812881624647,0.000249566849870861,0.00024945237812208746,0.0002493378729314902,0.00024922333431441987,0.0002491087622862317,0.0002489941568622853,0.00024887951805794477,0.00024876484588857875,0.00024865014036956027,0.0002485354015162668,0.00024842062934408044,0.00024830582386838756,0.0002481909851045792,0.00024807611306805065,0.0002479612077742018,0.000247846269238437,0.00024773129747616507,0.0002476162925027991,0.0002475012543337568,0.0002473861829844603,0.00024727107847033627,0.0002471559408068156,0.0002470407700093338,0.00024692556609333085,0.00024681032907425106,0.0002466950589675431,0.0002465797557886603,0.0002464644195530603,0.0002463490502762052,0.0002462336479735615,0.00024611821266060015,0.00024600274435279646,0.0002458872430656303,0.0002457717088145859,0.00024565614161515176,0.000245540541482821,0.0002454249084330912,0.00024530924248146403,0.0002451935436434459,0.0002450778119345475,0.00024496204737028396,0.0002448462499661747,0.0002447304197377437,0.0002446145567005193,0.0002444986608700341,0.00024438273226182525,0.0002442667708914343,0.00024415077677440706,0.0002440347499262939,0.0002439186903626494,0.0002438025980990327,0.00024368647315100726,0.00024357031553414075,0.0002434541252640055,0.00024333790235617805,0.0002432216468262394,0.00024310535868977477,0.00024298903796237395,0.00024287268465963103,0.0002427562987971443,0.00024263988039051673,0.0002425234294553554,0.0002424069460072718,0.00024229043006188187,0.00024217388163480586,0.0002420573007416683,0.0002419406873980982,0.00024182404161972882,0.0002417073634221978,0.00024159065282114718,0.00024147390983222318,0.0002413571344710766,0.00024124032675336245,0.00024112348669473997,0.00024100661431087294,0.0002408897096174294,0.00024077277263008168,0.00024065580336450642,0.00024053880183638464,0.00024042176806140177,0.00024030470205524735,0.00024018760383361546,0.0002400704734122043,0.0002399533108067166,0.00023983611603285913,0.00023971888910634333,0.00023960163004288458,0.00023948433885820288,0.00023936701556802234,0.00023924966018807134,0.00023913227273408282,0.00023901485322179377,0.00023889740166694554,0.00023877991808528385,0.0002386624024925586,0.0002385448549045241,0.00023842727533693884,0.00023830966380556574,0.00023819202032617182,0.00023807434491452848,0.00023795663758641148,0.00023783889835760072,0.0002377211272438804,0.0002376033242610391,0.00023748548942486956,0.00023736762275116885,0.00023724972425573823,0.00023713179395438335,0.00023701383186291409,0.00023689583799714443,0.00023677781237289286,0.00023665975500598195,0.0002365416659122386,0.00023642354510749396,0.00023630539260758337,0.00023618720842834656,0.00023606899258562733,0.00023595074509527383,0.00023583246597313844,0.0002357141552350777,0.00023559581289695261,0.00023547743897462815,0.0002353590334839737,0.00023524059644086269,0.00023512212786117305,0.00023500362776078673,0.00023488509615558994,0.00023476653306147324,0.00023464793849433115,0.0002345293124700627,0.000234410655004571,0.0002342919661137633,0.0002341732458135512,0.0002340544941198505,0.00023393571104858105,0.00023381689661566713,0.0002336980508370371,0.00023357917372862348,0.00023346026530636306,0.0002333413255861969,0.0002332223545840701,0.000233103352315932,0.00023298431879773622,0.00023286525404544054,0.00023274615807500674,0.00023262703090240106,0.00023250787254359382,0.00023238868301455945,0.00023226946233127657,0.00023215021050972814,0.00023203092756590108,0.0002319116135157866,0.00023179226837538006,0.00023167289216068096,0.00023155348488769305,0.00023143404657242412,0.00023131457723088618,0.00023119507687909544,0.00023107554553307224,0.00023095598320884103,0.0002308363899224305,0.00023071676568987338,0.00023059711052720664,0.00023047742445047136,0.00023035770747571274,0.00023023795961898028,0.00023011818089632732,0.00022999837132381155,0.00022987853091749485,0.00022975865969344304,0.00022963875766772622,0.00022951882485641853,0.0002293988612755984,0.00022927886694134805,0.0002291588418697542,0.00022903878607690752,0.00022891869957890272,0.00022879858239183878,0.00022867843453181866,0.00022855825601494955,0.00022843804685734268,0.00022831780707511338,0.0002281975366843812,0.00022807723570126957,0.00022795690414190625,0.00022783654202242296,0.00022771614935895564,0.00022759572616764412,0.00022747527246463252,0.00022735478826606901,0.00022723427358810572,0.00022711372844689903,0.0002269931528586093,0.0002268725468394011,0.00022675191040544287,0.0002266312435729073,0.0002265105463579711,0.00022638981877681506,0.00022626906084562403,0.0002261482725805869,0.00022602745399789674,0.00022590660511375048,0.00022578572594434936,0.00022566481650589847,0.00022554387681460712,0.00022542290688668852,0.00022530190673836006,0.00022518087638584316,0.00022505981584536322,0.00022493872513314975,0.00022481760426543628,0.0002246964532584604,0.0002245752721284637,0.00022445406089169185,0.00022433281956439461,0.0002242115481628256,0.00022409024670324264,0.0002239689152019075,0.000223847553675086,0.00022372616213904803,0.00022360474061006738,0.00022348328910442198,0.00022336180763839374,0.00022324029622826852,0.00022311875489033632,0.0002229971836408911,0.00022287558249623076,0.00022275395147265727,0.00022263229058647665,0.00022251059985399887,0.00022238887929153784,0.00022226712891541158,0.00022214534874194213,0.0002220235387874553,0.00022190169906828117,0.00022177982960075362,0.00022165793040121066,0.00022153600148599415,0.00022141404287145,0.0002212920545739282,0.00022117003660978245,0.00022104798899537072,0.00022092591174705474,0.00022080380488120045,0.00022068166841417744,0.0002205595023623595,0.0002204373067421244,0.00022031508156985372,0.00022019282686193306,0.0002200705426347521,0.00021994822890470436,0.00021982588568818722,0.00021970351300160226,0.0002195811108613549,0.0002194586792838543,0.00021933621828551397,0.00021921372788275098,0.00021909120809198666,0.00021896865892964598,0.0002188460804121581,0.00021872347255595597,0.00021860083537747659,0.00021847816889316066,0.0002183554731194531,0.00021823274807280263,0.0002181099937696618,0.00021798721022648723,0.00021786439745973937,0.00021774155548588263,0.0002176186843213853,0.00021749578398271965,0.00021737285448636179,0.00021724989584879178,0.0002171269080864935,0.00021700389121595489,0.0002168808452536677,0.00021675777021612754,0.00021663466611983404,0.0002165115329812906,0.0002163883708170046,0.00021626517964348722,0.00021614195947725363,0.00021601871033482284,0.00021589543223271776,0.0002157721251874651,0.0002156487892155956,0.00021552542433364376,0.00021540203055814806,0.0002152786079056507,0.00021515515639269786,0.00021503167603583955,0.00021490816685162974,0.00021478462885662607,0.0002146610620673903,0.00021453746650048787,0.00021441384217248805,0.00021429018909996405,0.000214166507299493,0.00021404279678765572,0.00021391905758103694,0.00021379528969622536,0.00021367149314981343,0.0002135476679583973,0.0002134238141385771,0.0002132999317069569,0.00021317602068014445,0.00021305208107475138,0.00021292811290739313,0.00021280411619468913,0.00021268009095326223,0.00021255603719973957,0.00021243195495075184,0.00021230784422293368,0.00021218370503292344,0.00021205953739736338,0.00021193534133289954,0.0002118111168561817,0.00021168686398386353,0.00021156258273260253,0.00021143827311905994,0.0002113139351599008,0.00021118956887179396,0.00021106517427141221,0.00021094075137543194,0.0002108163002005333,0.00021069182076340046,0.00021056731308072117,0.00021044277716918713,0.00021031821304549366,0.00021019362072634002,0.00021006900022842916,0.00020994435156846777,0.0002098196747631664,0.00020969496982923934,0.0002095702367834046,0.00020944547564238412,0.00020932068642290344,0.000209195869141692,0.0002090710238154828,0.0002089461504610127,0.0002088212490950225,0.00020869631973425645,0.00020857136239546277,0.00020844637709539337,0.00020832136385080395,0.00020819632267845374,0.00020807125359510598,0.00020794615661752754,0.00020782103176248903,0.00020769587904676483,0.000207570698487133,0.00020744549010037552,0.0002073202539032777,0.00020719498991262895,0.00020706969814522226,0.00020694437861785433,0.0002068190313473257,0.0002066936563504405,0.0002065682536440067,0.00020644282324483576,0.00020631736516974302,0.00020619187943554757,0.00020606636605907216,0.0002059408250571432,0.00020581525644659086,0.00020568966024424903,0.0002055640364669551,0.0002054383851315504,0.00020531270625487994,0.00020518699985379226,0.00020506126594513967,0.0002049355045457783,0.00020480971567256778,0.00020468389934237137,0.00020455805557205626,0.00020443218437849313,0.00020430628577855644,0.0002041803597891242,0.00020405440642707828,0.00020392842570930405,0.00020380241765269056,0.00020367638227413058,0.00020355031959052062,0.00020342422961876067,0.0002032981123757545,0.00020317196787840956,0.0002030457961436369,0.00020291959718835107,0.00020279337102947057,0.00020266711768391734,0.00020254083716861709,0.00020241452950049902,0.0002022881946964961,0.0002021618327735449,0.00020203544374858571,0.00020190902763856218,0.00020178258446042183,0.00020165611423111584,0.00020152961696759882,0.0002014030926868292,0.0002012765414057689,0.00020114996314138356,0.00020102335791064233,0.00020089672573051802,0.00020077006661798702,0.00020064338059002949,0.00020051666766362903,0.00020038992785577283,0.00020026316118345192,0.00020013636766366054,0.0002000095473133969,0.00019988270014966258,0.00019975582618946287,0.00019962892544980664,0.00019950199794770626,0.00019937504370017784,0.0001992480627242409,0.00019912105503691867,0.00019899402065523788,0.00019886695959622894,0.00019873987187692574,0.0001986127575143658,0.00019848561652559027,0.0001983584489276436,0.00019823125473757415,0.00019810403397243364,0.00019797678664927742,0.00019784951278516437,0.000197722212397157,0.0001975948855023213,0.00019746753211772678,0.0001973401522604466,0.0001972127459475574,0.00019708531319613943,0.00019695785402327643,0.00019683036844605567,0.0001967028564815681,0.00019657531814690796,0.00019644775345917318,0.00019632016243546524,0.0001961925450928891,0.0001960649014485533,0.00019593723151956985,0.00019580953532305433,0.0001956818128761257,0.00019555406419590664,0.00019542628929952326,0.00019529848820410518,0.0001951706609267855,0.0001950428074847009,0.00019491492789499166,0.00019478702217480117,0.00019465909034127677,0.00019453113241156908,0.00019440314840283226,0.000194275138332224,0.00019414710221690541,0.00019401904007404125,0.00019389095192079946,0.00019376283777435178,0.00019363469765187327,0.00019350653157054255,0.00019337833954754166,0.00019325012160005618,0.0001931218777452751,0.000192993608000391,0.00019286531238259968,0.0001927369909091007,0.0001926086435970969,0.00019248027046379464,0.00019235187152640378,0.00019222344680213763,0.00019209499630821293,0.00019196652006184977,0.00019183801808027187,0.00019170949038070631,0.00019158093698038367,0.00019145235789653792,0.00019132375314640648,0.00019119512274723034,0.00019106646671625366,0.00019093778507072421,0.0001908090778278932,0.00019068034500501532,0.0001905515866193485,0.00019042280268815427,0.0001902939932286976,0.00019016515825824666,0.00019003629779407324,0.00018990741185345253,0.0001897785004536631,0.0001896495636119869,0.00018952060134570935,0.00018939161367211932,0.0001892626006085089,0.00018913356217217374,0.0001890044983804129,0.00018887540925052875,0.0001887462947998271,0.00018861715504561721,0.00018848799000521172,0.00018835879969592644,0.00018822958413508087,0.00018810034333999775,0.0001879710773280032,0.00018784178611642682,0.00018771246972260143,0.0001875831281638634,0.00018745376145755228,0.00018732436962101115,0.00018719495267158635,0.00018706551062662772,0.00018693604350348831,0.00018680655131952467,0.0001866770340920967,0.00018654749183856745,0.00018641792457630349,0.00018628833232267483,0.0001861587150950547,0.00018602907291081968,0.00018589940578734974,0.0001857697137420283,0.00018563999679224177,0.00018551025495538024,0.00018538048824883702,0.00018525069669000877,0.00018512088029629546,0.0001849910390851004,0.00018486117307383034,0.000184731282279895,0.0001846013667207078,0.00018447142641368538,0.0001843414613762476,0.0001842114716258177,0.00018408145717982227,0.00018395141805569113,0.00018382135427085755,0.00018369126584275781,0.00018356115278883182,0.0001834310151265227,0.0001833008528732767,0.00018317066604654357,0.00018304045466377628,0.00018291021874243117,0.00018277995829996764,0.00018264967335384857,0.0001825193639215401,0.00018238903002051172,0.00018225867166823598,0.00018212828888218894,0.00018199788167984988,0.00018186745007870117,0.00018173699409622867,0.0001816065137499214,0.00018147600905727175,0.00018134548003577528,0.0001812149267029308,0.0001810843490762405,0.00018095374717320962,0.00018082312101134682,0.00018069247060816397,0.00018056179598117622,0.00018043109714790189,0.00018030037412586266,0.00018016962693258336,0.00018003885558559203,0.00017990806010241997,0.00017977724050060188,0.00017964639679767544,0.00017951552901118175,0.00017938463715866504,0.00017925372125767288,0.00017912278132575584,0.00017899181738046792,0.0001788608294393663,0.00017872981752001127,0.00017859878163996648,0.0001784677218167987,0.00017833663806807805,0.00017820553041137754,0.00017807439886427368,0.0001779432434443461,0.0001778120641691776,0.00017768086105635422,0.00017754963412346518,0.00017741838338810294,0.00017728710886786295,0.00017715581058034408,0.0001770244885431483,0.0001768931427738808,0.00017676177329014985,0.00017663038010956703,0.00017649896324974709,0.00017636752272830774,0.0001762360585628701,0.0001761045707710584,0.0001759730593705,0.00017584152437882545,0.00017570996581366848,0.00017557838369266598,0.00017544677803345786,0.00017531514885368735,0.00017518349617100083,0.00017505182000304774,0.0001749201203674807,0.00017478839728195556,0.00017465665076413117,0.0001745248808316697,0.0001743930875022362,0.00017426127079349913,0.00017412943072312985,0.00017399756730880308,0.0001738656805681965,0.00017373377051899095,0.00017360183717887056,0.00017346988056552223,0.0001733379006966363,0.0001732058975899061,0.0001730738712630281,0.00017294182173370186,0.00017280974901963007,0.00017267765313851862,0.00017254553410807626,0.00017241339194601504,0.00017228122667005007,0.00017214903829789957,0.00017201682684728483,0.00017188459233593025,0.0001717523347815634,0.00017162005420191464,0.00017148775061471777,0.00017135542403770956,0.00017122307448862973,0.0001710907019852213,0.00017095830654523017,0.00017082588818640555,0.00017069344692649936,0.0001705609827832669,0.00017042849577446643,0.00017029598591785928,0.0001701634532312099,0.0001700308977322857,0.00016989831943885726,0.00016976571836869802,0.0001696330945395847,0.00016950044796929694,0.0001693677786756175,0.00016923508667633216,0.00016910237198922967,0.000168969634632102,0.00016883687462274395,0.00016870409197895347,0.00016857128671853152,0.00016843845885928214,0.00016830560841901232,0.00016817273541553214,0.00016803983986665477,0.00016790692179019615,0.00016777398120397543,0.00016764101812581482,0.00016750803257353946,0.0001673750245649775,0.00016724199411796015,0.00016710894125032165,0.00016697586597989907,0.00016684276832453266,0.00016670964830206562,0.00016657650593034413,0.0001664433412272174,0.00016631015421053765,0.00016617694489816013,0.00016604371330794276,0.00016591045945774688,0.00016577718336543659,0.00016564388504887903,0.00016551056452594425,0.00016537722181450535,0.0001652438569324384,0.00016511046989762246,0.00016497706072793943,0.0001648436294412743,0.00016471017605551502,0.00016457670058855247,0.00016444320305828046,0.00016430968348259587,0.00016417614187939848,0.00016404257826659087,0.00016390899266207877,0.00016377538508377084,0.0001636417555495786,0.00016350810407741653,0.00016337443068520214,0.0001632407353908558,0.00016310701821230076,0.00016297327916746333,0.00016283951827427266,0.00016270573555066087,0.00016257193101456305,0.0001624381046839171,0.00016230425657666402,0.00016217038671074744,0.00016203649510411418,0.00016190258177471384,0.00016176864674049903,0.00016163469001942516,0.00016150071162945057,0.00016136671158853668,0.0001612326899146475,0.0001610986466257501,0.00016096458173981454,0.00016083049527481364,0.00016069638724872318,0.0001605622576795218,0.00016042810658519112,0.0001602939339837154,0.00016015973989308202,0.0001600255243312812,0.00015989128731630595,0.0001597570288661523,0.00015962274899881896,0.00015948844773230777,0.0001593541250846231,0.00015921978107377247,0.00015908541571776617,0.0001589510290346173,0.0001588166210423419,0.00015868219175895883,0.0001585477412024899,0.00015841326939095953,0.0001582787763423952,0.00015814426207482713,0.0001580097266062885,0.00015787516995481525,0.00015774059213844615,0.00015760599317522292,0.00015747137308318987,0.0001573367318803944,0.0001572020695848866,0.0001570673862147194,0.00015693268178794867,0.00015679795632263298,0.00015666320983683378,0.0001565284423486152,0.00015639365387604438,0.00015625884443719117,0.00015612401405012827,0.00015598916273293115,0.00015585429050367814,0.0001557193973804503,0.00015558448338133163,0.00015544954852440867,0.00015531459282777101,0.0001551796163095109,0.00015504461898772348,0.00015490960088050657,0.00015477456200596083,0.0001546395023821898,0.00015450442202729952,0.0001543693209593991,0.0001542341991966003,0.00015409905675701767,0.00015396389365876853,0.000153828709919973,0.00015369350555875398,0.000153558280593237,0.00015342303504155047,0.00015328776892182554,0.00015315248225219614,0.00015301717505079892,0.0001528818473357733,0.00015274649912526148,0.00015261113043740828,0.0001524757412903614,0.00015234033170227122,0.00015220490169129088,0.00015206945127557633,0.0001519339804732861,0.00015179848930258163,0.00015166297778162682,0.00015152744592858864,0.00015139189376163652,0.00015125632129894275,0.0001511207285586823,0.0001509851155590329,0.000150849482318175,0.00015071382885429156,0.00015057815518556848,0.00015044246133019432,0.00015030674730636036,0.0001501710131322605,0.00015003525882609141,0.00014989948440605254,0.00014976368989034575,0.00014962787529717588,0.00014949204064475038,0.00014935618595127932,0.00014922031123497555,0.00014908441651405457,0.0001489485018067346,0.00014881256713123638,0.0001486766125057835,0.00014854063794860213,0.0001484046434779212,0.00014826862911197227,0.00014813259486898953,0.0001479965407672099,0.00014786046682487285,0.00014772437306022058,0.000147588259491498,0.00014745212613695262,0.00014731597301483455,0.00014717980014339668,0.00014704360754089454,0.00014690739522558606,0.00014677116321573208,0.000146634911529596,0.00014649864018544383,0.0001463623492015443,0.0001462260385961686,0.00014608970838759085,0.00014595335859408736,0.00014581698923393747,0.00014568060032542292,0.00014554419188682818,0.0001454077639364403,0.00014527131649254887,0.00014513484957344626,0.0001449983631974274,0.00014486185738278956,0.00014472533214783304,0.00014458878751086044,0.0001444522234901771,0.00014431564010409096,0.00014417903737091244,0.0001440424153089548,0.0001439057739365335,0.00014376911327196695,0.00014363243333357593,0.00014349573413968393,0.000143359015708617,0.00014322227805870367,0.00014308552120827529,0.00014294874517566537,0.00014281194997921038,0.00014267513563724917,0.0001425383021681232,0.00014240144959017656,0.00014226457792175577,0.00014212768718121005,0.000141990777386891,0.00014185384855715293,0.00014171690071035264,0.00014157993386484949,0.0001414429480390054,0.00014130594325118483,0.00014116891951975483,0.00014103187686308473,0.00014089481529954678,0.0001407577348475155,0.00014062063552536808,0.00014048351735148414,0.0001403463803442459,0.00014020922452203817,0.000140072049903248,0.00013993485650626525,0.00013979764434948218,0.00013966041345129363,0.00013952316383009685,0.00013938589550429166,0.0001392486084922805,0.00013911130281246798,0.00013897397848326156,0.00013883663552307108,0.00013869927395030883,0.00013856189378338963,0.00013842449504073082,0.00013828707774075232,0.00013814964190187617,0.00013801218754252732,0.00013787471468113297,0.00013773722333612292,0.00013759971352592934,0.00013746218526898695,0.00013732463858373299,0.00013718707348860695,0.00013704949000205104,0.00013691188814250976,0.00013677426792843022,0.0001366366293782619,0.00013649897251045672,0.0001363612973434692,0.00013622360389575606,0.00013608589218577668,0.00013594816223199278,0.00013581041405286864,0.00013567264766687086,0.0001355348630924686,0.00013539706034813327,0.00013525923945233905,0.00013512140042356213,0.0001349835432802814,0.0001348456680409781,0.000134707774724136,0.00013456986334824112,0.00013443193393178205,0.00013429398649324978,0.00013415602105113755,0.00013401803762394122,0.00013388003623015894,0.00013374201688829136,0.00013360397961684144,0.0001334659244343146,0.00013332785135921872,0.00013318976041006388,0.00013305165160536274,0.0001329135249636303,0.00013277538050338397,0.0001326372182431435,0.0001324990382014311,0.00013236084039677134,0.000132222624847691,0.0001320843915727195,0.00013194614059038853,0.00013180787191923208,0.00013166958557778665,0.000131531281584591,0.0001313929599581864,0.00013125462071711622,0.0001311162638799264,0.0001309778894651652,0.00013083949749138327,0.00013070108797713352,0.00013056266094097128,0.00013042421640145426,0.00013028575437714235,0.00013014727488659797,0.00013000877794838578,0.00012987026358107288,0.0001297317318032286,0.0001295931826334246,0.00012945461609023505,0.00012931603219223616,0.00012917743095800665,0.00012903881240612755,0.00012890017655518222,0.00012876152342375632,0.00012862285303043777,0.00012848416539381697,0.00012834546053248636,0.00012820673846504092,0.00012806799921007787,0.00012792924278619668,0.00012779046921199922,0.0001276516785060896,0.00012751287068707431,0.00012737404577356192,0.00012723520378416344,0.00012709634473749223,0.00012695746865216384,0.00012681857554679615,0.00012667966544000926,0.0001265407383504257,0.00012640179429667002,0.00012626283329736926,0.00012612385537115266,0.0001259848605366517,0.00012584584881250024,0.00012570682021733424,0.00012556777476979206,0.00012542871248851436,0.00012528963339214372,0.00012515053749932538,0.00012501142482870662,0.00012487229539893705,0.00012473314922866848,0.00012459398633655496,0.00012445480674125293,0.0001243156104614207,0.00012417639751571922,0.00012403716792281144,0.00012389792170136265,0.00012375865887004033,0.00012361937944751418,0.00012348008345245624,0.00012334077090354043,0.00012320144181944328,0.00012306209621884337,0.00012292273412042146,0.0001227833555428606,0.000122643960504846,0.00012250454902506522,0.00012236512112220763,0.00012222567681496527,0.0001220862161220321,0.00012194673906210434,0.00012180724565388049,0.00012166773591606111,0.00012152820986734912,0.00012138866752644933,0.00012124910891206902,0.00012110953404291754,0.00012096994293770645,0.00012083033561514942,0.0001206907120939624,0.00012055107239286349,0.00012041141653057278,0.00012027174452581273,0.0001201320563973079,0.00011999235216378508,0.00011985263184397306,0.00011971289545660293,0.00011957314302040799,0.00011943337455412333,0.00011929359007648661,0.00011915378960623747,0.00011901397316211762,0.00011887414076287107,0.00011873429242724383,0.00011859442817398421,0.00011845454802184237,0.00011831465198957086,0.00011817474009592427,0.00011803481235965935,0.00011789486879953488,0.00011775490943431191,0.00011761493428275357,0.00011747494336362488,0.00011733493669569327,0.00011719491429772815,0.00011705487618850106,0.00011691482238678564,0.00011677475291135764,0.00011663466778099499,0.00011649456701447746,0.00011635445063058718,0.0001162143186481083,0.00011607417108582705,0.00011593400796253171,0.00011579382929701273,0.00011565363510806255,0.00011551342541447585,0.00011537320023504909,0.00011523295958858112,0.00011509270349387264,0.00011495243196972662,0.00011481214503494793,0.00011467184270834359,0.00011453152500872275,0.00011439119195489638,0.0001142508435656777,0.00011411047985988199,0.00011397010085632655,0.00011382970657383069,0.00011368929703121583,0.00011354887224730546,0.0001134084322409249,0.00011326797703090178,0.00011312750663606564,0.0001129870210752481,0.00011284652036728273,0.00011270600453100527,0.00011256547358525343,0.00011242492754886675,0.00011228436644068709,0.0001121437902795582,0.00011200319908432581,0.00011186259287383779,0.00011172197166694384,0.00011158133548249594,0.00011144068433934771,0.00011130001825635508,0.00011115933725237586,0.00011101864134626987,0.00011087793055689897,0.00011073720490312693,0.00011059646440381972,0.00011045570907784493,0.00011031493894407244,0.00011017415402137403,0.0001100333543286235,0.00010989253988469652,0.00010975171070847086,0.00010961086681882629,0.00010947000823464431,0.00010932913497480862,0.00010918824705820485,0.00010904734450372054,0.00010890642733024524,0.00010876549555667044,0.00010862454920188966,0.00010848358828479817,0.00010834261282429335,0.00010820162283927456,0.000108060618348643,0.00010791959937130192,0.00010777856592615643,0.0001076375180321137,0.00010749645570808256,0.00010735537897297405,0.00010721428784570109,0.00010707318234517845,0.00010693206249032287,0.000106790928300053,0.00010664977979328954,0.00010650861698895482,0.00010636743990597335,0.00010622624856327143,0.00010608504297977736,0.00010594382317442122,0.00010580258916613515,0.00010566134097385305,0.00010552007861651092,0.00010537880211304633,0.00010523751148239906,0.00010509620674351061,0.0001049548879153245,0.000104813555016786,0.00010467220806684236,0.00010453084708444281,0.00010438947208853811,0.00010424808309808123,0.0001041066801320269,0.00010396526320933177,0.00010382383234895433,0.00010368238756985489,0.00010354092889099581,0.00010339945633134094,0.00010325796990985639,0.0001031164696455099,0.00010297495555727115,0.00010283342766411168,0.00010269188598500481,0.00010255033053892589,0.00010240876134485176,0.00010226717842176143,0.00010212558178863562,0.00010198397146445695,0.0001018423474682098,0.00010170070981888042,0.000101559058535457,0.00010141739363692925,0.000101275715142289,0.00010113402307052979,0.00010099231744064701,0.00010085059827163785,0.00010070886558250132,0.00010056711939223831,0.00010042535971985128,0.00010028358658434475,0.00010014180000472497],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Iteration\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Learning Rate\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Learning Rate\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('68eca714-6f92-4464-80f5-9111f7c3e6c1');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding"
      ],
      "metadata": {
        "id": "KqJVxM8kv7tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wte = nn.Embedding(config.vocab_size, config.n_embd)  # Token embeddings\n",
        "wpe = nn.Embedding(config.block_size, config.n_embd)  # Position embeddings"
      ],
      "metadata": {
        "id": "GRKQg5s_v89o"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Components"
      ],
      "metadata": {
        "id": "awT66FoQyZYV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-head Attention\n",
        "Model components : MHA"
      ],
      "metadata": {
        "id": "BdXGKP4vwru7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-head causal self-attention.\n",
        "\n",
        "    Key difference from your previous class:\n",
        "    - Uses a causal mask to prevent attending to future tokens\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, n_heads, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % n_heads == 0, \"d_model must be divisible by n_heads\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_k = d_model // n_heads  # Dimension per head\n",
        "\n",
        "        # Linear projections for Q, K, V (all heads at once)\n",
        "        self.W_q = nn.Linear(d_model, d_model, bias=True) # passage à true car supposément meilleur\n",
        "        self.W_k = nn.Linear(d_model, d_model, bias=True)\n",
        "        self.W_v = nn.Linear(d_model, d_model, bias=True)\n",
        "\n",
        "        # Output projection\n",
        "        self.W_o = nn.Linear(d_model, d_model, bias=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor [batch_size, seq_len, d_model]\n",
        "\n",
        "        Returns:\n",
        "            Output tensor [batch_size, seq_len, d_model]\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, d_model = x.shape\n",
        "\n",
        "        # Linear projections\n",
        "        Q = self.W_q(x)  # [batch_size, seq_len, d_model]\n",
        "        K = self.W_k(x)\n",
        "        V = self.W_v(x)\n",
        "\n",
        "        # Split into multiple heads and reshape\n",
        "        # [batch_size, seq_len, d_model] -> [batch_size, seq_len, n_heads, d_k]\n",
        "        # -> [batch_size, n_heads, seq_len, d_k]\n",
        "        Q = Q.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        K = K.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        V = V.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "        # Scaled dot-product attention\n",
        "        # Compute attention scores\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "        # [batch_size, n_heads, seq_len, seq_len]\n",
        "\n",
        "        # Apply causal mask (prevent attending to future tokens)\n",
        "        mask = torch.tril(torch.ones(seq_len, seq_len, device=x.device)).bool()\n",
        "        scores = scores.masked_fill(~mask, float('-inf'))\n",
        "\n",
        "        # Apply softmax\n",
        "        attn_weights = F.softmax(scores, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Apply attention to values\n",
        "        out = torch.matmul(attn_weights, V)\n",
        "        # [batch_size, n_heads, seq_len, d_k]\n",
        "\n",
        "        # Concatenate heads\n",
        "        out = out.transpose(1, 2).contiguous().view(batch_size, seq_len, d_model)\n",
        "\n",
        "        # Output projection\n",
        "        out = self.W_o(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "5bNK6w9KwrPe"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feed-Forward Network\n",
        "Model components : Feed Forward"
      ],
      "metadata": {
        "id": "gLBckMy1xl1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    Position-wise Feed-Forward Network.\n",
        "    Two linear transformations with GELU activation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(d_ff, d_model),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "kd0c8817xj5Q"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Block\n",
        "Model components : transformer block"
      ],
      "metadata": {
        "id": "xcXJgrM6x4oZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A single transformer block:\n",
        "    - Multi-head attention with residual connection\n",
        "    - Feed-forward network with residual connection\n",
        "    - Layer normalization (pre-norm architecture)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(d_model)\n",
        "        self.attn = MultiHeadAttention(d_model, n_heads, dropout)\n",
        "        self.ln2 = nn.LayerNorm(d_model)\n",
        "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pre-norm architecture (more stable training)\n",
        "        # Attention with residual\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        # Feed-forward with residual\n",
        "        x = x + self.ff(self.ln2(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "wiw-o6m7yA08"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complete transformer model"
      ],
      "metadata": {
        "id": "mtSrDtssyOlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTModel(nn.Module):\n",
        "    \"\"\"\n",
        "    A minimal GPT-style transformer for next token prediction.\n",
        "\n",
        "    Architecture:\n",
        "    1. Token embeddings + positional embeddings\n",
        "    2. Stack of transformer blocks\n",
        "    3. Layer norm\n",
        "    4. Linear head to predict next token\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # Token embeddings\n",
        "        self.token_embedding = nn.Embedding(vocab_size, config.d_model)\n",
        "\n",
        "        # Positional embeddings (learned)\n",
        "        self.pos_embedding = nn.Embedding(config.block_size, config.d_model)\n",
        "\n",
        "        # Transformer blocks\n",
        "        self.blocks = nn.ModuleList([\n",
        "            TransformerBlock(config.d_model, config.n_heads, config.d_ff, config.dropout)\n",
        "            for _ in range(config.n_layers)\n",
        "        ])\n",
        "\n",
        "        # Final layer norm\n",
        "        self.ln_f = nn.LayerNorm(config.d_model)\n",
        "\n",
        "        # Language modeling head\n",
        "        self.lm_head = nn.Linear(config.d_model, vocab_size, bias=False)\n",
        "\n",
        "        # Weight tying (share weights between token embeddings and lm_head)\n",
        "        self.token_embedding.weight = self.lm_head.weight\n",
        "\n",
        "        # Initialize weights\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "        # Report number of parameters\n",
        "        n_params = sum(p.numel() for p in self.parameters())\n",
        "        print(f\"Number of parameters: {n_params/1e6:.2f}M\")\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            idx: Input token indices [batch_size, seq_len]\n",
        "            targets: Target token indices [batch_size, seq_len] (optional)\n",
        "\n",
        "        Returns:\n",
        "            logits: Output logits [batch_size, seq_len, vocab_size]\n",
        "            loss: Cross-entropy loss (if targets provided)\n",
        "        \"\"\"\n",
        "        batch_size, seq_len = idx.shape\n",
        "\n",
        "        # Token embeddings\n",
        "        tok_emb = self.token_embedding(idx)  # [batch_size, seq_len, d_model]\n",
        "\n",
        "        # Positional embeddings\n",
        "        pos = torch.arange(0, seq_len, dtype=torch.long, device=idx.device)\n",
        "        pos_emb = self.pos_embedding(pos)  # [seq_len, d_model]\n",
        "\n",
        "        # Add embeddings\n",
        "        x = tok_emb + pos_emb  # Broadcasting happens automatically\n",
        "\n",
        "        # Apply transformer blocks\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        # Final layer norm\n",
        "        x = self.ln_f(x)\n",
        "\n",
        "        # Language modeling head\n",
        "        logits = self.lm_head(x)  # [batch_size, seq_len, vocab_size]\n",
        "\n",
        "        # Compute loss if targets are provided\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            # Reshape for cross-entropy\n",
        "            B, T, C = logits.shape\n",
        "            logits_flat = logits.view(B * T, C)\n",
        "            targets_flat = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits_flat, targets_flat)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
        "        \"\"\"\n",
        "        Generate new tokens autoregressively.\n",
        "\n",
        "        Args:\n",
        "            idx: Starting sequence [batch_size, seq_len]\n",
        "            max_new_tokens: Number of tokens to generate\n",
        "            temperature: Sampling temperature (higher = more random)\n",
        "            top_k: If set, only sample from top k tokens\n",
        "\n",
        "        Returns:\n",
        "            Generated sequence [batch_size, seq_len + max_new_tokens]\n",
        "        \"\"\"\n",
        "        for _ in range(max_new_tokens):\n",
        "            # Crop context if needed (to fit block_size)\n",
        "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
        "\n",
        "            # Forward pass\n",
        "            logits, _ = self(idx_cond)\n",
        "\n",
        "            # Focus on last time step\n",
        "            logits = logits[:, -1, :] / temperature  # [batch_size, vocab_size]\n",
        "\n",
        "            # Optionally crop logits to only top k options\n",
        "            if top_k is not None:\n",
        "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
        "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "            # Append to sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "        return idx"
      ],
      "metadata": {
        "id": "TJQ6AEYeyVJA"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instanciate the model"
      ],
      "metadata": {
        "id": "MC3j4BdEz8-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "model = GPTModel(config.vocab_size, config).to(device)\n",
        "\n",
        "# Print model architecture\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrinwPKIz-zL",
        "outputId": "e105710e-524f-4fa8-f034-0516bc77c237"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 27.63M\n",
            "GPTModel(\n",
            "  (token_embedding): Embedding(50257, 384)\n",
            "  (pos_embedding): Embedding(128, 384)\n",
            "  (blocks): ModuleList(\n",
            "    (0-5): 6 x TransformerBlock(\n",
            "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=384, out_features=384, bias=True)\n",
            "        (W_k): Linear(in_features=384, out_features=384, bias=True)\n",
            "        (W_v): Linear(in_features=384, out_features=384, bias=True)\n",
            "        (W_o): Linear(in_features=384, out_features=384, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff): FeedForward(\n",
            "        (net): Sequential(\n",
            "          (0): Linear(in_features=384, out_features=1024, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=1024, out_features=384, bias=True)\n",
            "          (3): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "  (lm_head): Linear(in_features=384, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate from untrained model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated = model.generate(context, max_new_tokens=200, temperature=1.0, top_k=10)\n",
        "print('\\n=== Untrained Model Generation ===')\n",
        "print(enc.decode(generated[0].tolist()))\n",
        "print('=' * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iminfjNwCMKr",
        "outputId": "e2a0ebf7-4106-4865-a510-343fe1da8d4f"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Untrained Model Generation ===\n",
            "! Thief esche ministry Display Display cabinet optimum audiences hesitate ThiefitcherPred hesitate CENT CENT0404 Bones updating477477 subp confidential subp Seek HAL cabinet casinos improvingPH cabinet bullyingPH negro Amy mul explore Hob Shameslaveaca Flask wandering bloodstreamslave reproduced zonesoux sculpturesanamo Sof Sof Ct spotlight wearer euro AnkaraCs sizedUTION Vader 6000 incorrectlyubric Shameubric teamsMel exploreServices spotlight FIGHT mismatchCorDark subp Venezuela Hor improvingServices Baghd afforded linebackers VaderDisplay illegal illegal Sof policymakers Yahoobour Emily parted linebackers updating Ankaraission Teachers Macro thrott impressions Jah Shame radicals radicals linebackersbour spotlightFA-+reditation linebackers nonsensicalamiyaSteam hitterVT Favorite larg Goldberg revenge rig impressions impressionsanut Cyprusategic Bold Bold doom Bold Bold FIGHTFAFAFA craz�minimumUCTreements cohesionFA cheek Second clash hated sclerosis>>\\odes oft sclerosis cabinet oftephStaff victories propertyCalifornia Lawn hardships Howarddistance (# apologizeditting Baal iter esports Rover Roverarrasschesterarians forgiveness Romeo insistenceoupleags requHere Roverarrassenburg comments Vehicles Roverreementsgey HAL HALittinghyde glareeph ominreementsERTrestlingiot\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train setup"
      ],
      "metadata": {
        "id": "bfUAFiD9BugQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer"
      ],
      "metadata": {
        "id": "PPGWWwMAByLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)"
      ],
      "metadata": {
        "id": "RcODYm7rBuKI"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split training data"
      ],
      "metadata": {
        "id": "udaw-wbyFXXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_stories = ds[\"train\"][\"story\"]\n",
        "n_stories = len(all_stories)\n",
        "n_test = n_stories //8\n",
        "n_train = n_stories - n_test\n",
        "\n",
        "train_stories = np.random.choice(all_stories, n_train, replace=False)\n",
        "test_stories = np.setdiff1d(all_stories, train_stories)"
      ],
      "metadata": {
        "id": "hzpBbQtwFZXo"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate train and test stories, and tokenize them\n",
        "train_data = enc.encode(\" \".join(train_stories))\n",
        "test_data = enc.encode(\" \".join(test_stories))"
      ],
      "metadata": {
        "id": "cPskIz8bKO9u"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print length (# of tokens) if train and test data\n",
        "print(f\"Train data length: {len(train_data)} tokens, corresponding to {len(\" \".join(train_stories)):4f} characters\")\n",
        "print(f\"Test data length: {len(test_data)} tokens, corresponding to {len(\" \".join(test_stories))} characters\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXiSIA2efhyJ",
        "outputId": "30148be5-dc90-4322-9928-396d817b82d7"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data length: 515117 tokens, corresponding to 2501190.000000 characters\n",
            "Test data length: 62804 tokens, corresponding to 302983 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batching"
      ],
      "metadata": {
        "id": "NujS5w0lGOoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch_r(split, config, iter=0):\n",
        "  if split == 'train':\n",
        "    data = train_data\n",
        "  elif split == 'test':\n",
        "    data = test_data\n",
        "  else : return None\n",
        "  # rnadomly select starting position\n",
        "  ix = torch.randint(len(data) - config.block_size, (config.batch_size,))\n",
        "  # in and target sequence\n",
        "  x = torch.stack([torch.tensor(data[i:i+config.block_size]) for i in ix])\n",
        "  y = torch.stack([torch.tensor(data[i+1:i+config.block_size+1]) for i in ix])\n",
        "  # send to device\n",
        "  x, y = x.to(device), y.to(device)\n",
        "  return x, y\n",
        "\n",
        "def get_batch_d(split, config, iter):\n",
        "  if split == 'train':\n",
        "    data = train_data\n",
        "    len_data = len(train_data)\n",
        "  elif split == 'test':\n",
        "    data = test_data\n",
        "    len_data = len(test_data)\n",
        "  else : return None\n",
        "  # rnadomly select starting position\n",
        "  #ix = torch.randint(len(data) - config.block_size, (config.batch_size,))\n",
        "  ix = torch.ones(config.batch_size, dtype=torch.int64) * (iter * config.batch_size)%len_data\n",
        "  # in and target sequence\n",
        "  x = torch.stack([torch.tensor(data[i:i+config.block_size]) for i in ix])\n",
        "  y = torch.stack([torch.tensor(data[i+1:i+config.block_size+1]) for i in ix])\n",
        "  # send to device\n",
        "  x, y = x.to(device), y.to(device)\n",
        "  return x, y"
      ],
      "metadata": {
        "id": "ECL7PeWfMtHE"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test batching batchi batch\n",
        "print(\"=\"*40)\n",
        "xb, yb = get_batch_r('train', config)\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(enc.decode(xb[0].tolist()))\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(enc.decode(yb[0].tolist()))\n",
        "\n",
        "print(\"=\"*40)\n",
        "xb, yb = get_batch_d('train', config, 0)\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(enc.decode(xb[0].tolist()))\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(enc.decode(yb[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFyaTq28aC8U",
        "outputId": "db885c15-137c-4526-b9c5-5bdd35e81602"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================\n",
            "inputs:\n",
            "torch.Size([32, 128])\n",
            " the jungle, they stumbled upon ancient ruins overrun by thick vines and guarded by hidden traps. Guided by faded maps and cryptic clues, they pressed on, their excitement mounting with each step closer to uncovering the idol's secrets.  But they were not alone in their quest. A rival group of treasure hunters, led by the notorious mercenary, Captain Rodriguez, lurked in the shadows, intent on claiming the idol for themselves. A race against time ensued, as both parties navigated perilous obstacles and battled unforgiving elements.  Finally, deep within a hidden chamber, Dr. Rivers and her team stumbled upon the legendary artifact, gleaming\n",
            "targets:\n",
            "torch.Size([32, 128])\n",
            " jungle, they stumbled upon ancient ruins overrun by thick vines and guarded by hidden traps. Guided by faded maps and cryptic clues, they pressed on, their excitement mounting with each step closer to uncovering the idol's secrets.  But they were not alone in their quest. A rival group of treasure hunters, led by the notorious mercenary, Captain Rodriguez, lurked in the shadows, intent on claiming the idol for themselves. A race against time ensued, as both parties navigated perilous obstacles and battled unforgiving elements.  Finally, deep within a hidden chamber, Dr. Rivers and her team stumbled upon the legendary artifact, gleaming with\n",
            "========================================\n",
            "inputs:\n",
            "torch.Size([32, 128])\n",
            "Amidst the vibrant streets of Rio de Janeiro, where samba rhythms filled the air and the scent of tropical flowers danced on the breeze, Sofia found herself swept away by a love as passionate as the Brazilian sun. André, a local musician with a soul as colorful as the carnival parade, stole her heart with his infectious laughter and his tender melodies.  Their romance unfolded amidst the pulsating energy of the city's nightlife and the tranquil beauty of its beaches. With each shared caipirinha at a lively bar and each moonlit stroll along Copacabana, Sofia felt herself drawn to André's z\n",
            "targets:\n",
            "torch.Size([32, 128])\n",
            "st the vibrant streets of Rio de Janeiro, where samba rhythms filled the air and the scent of tropical flowers danced on the breeze, Sofia found herself swept away by a love as passionate as the Brazilian sun. André, a local musician with a soul as colorful as the carnival parade, stole her heart with his infectious laughter and his tender melodies.  Their romance unfolded amidst the pulsating energy of the city's nightlife and the tranquil beauty of its beaches. With each shared caipirinha at a lively bar and each moonlit stroll along Copacabana, Sofia felt herself drawn to André's zest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "8qeOUQE9GW4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss(model, config):\n",
        "    \"\"\"\n",
        "    Estimate loss on train and validation sets.\n",
        "    \"\"\"\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'test']:\n",
        "        losses = torch.zeros(config.eval_iters)\n",
        "        for k in range(config.eval_iters):\n",
        "            X, Y = get_batch_r(split, config)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ],
      "metadata": {
        "id": "Z5isQE8LNVOX"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save model parameters\n",
        "random_n_model = np.random.randint(1000, 10000)\n",
        "with open(f'model_{random_n_model}.txt', 'w') as f:\n",
        "    f.write(str(model))\n",
        "print(\"Saved model description\")\n",
        "files.download(f'model_{random_n_model}.txt')\n",
        "print(\"Downloaded model description\")\n",
        "\n",
        "\n",
        "# Training loop\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "iterations = []\n",
        "\n",
        "print('Starting training...')\n",
        "print(f'Training for {config.max_iters} iterations')\n",
        "print(f'Evaluating every {config.eval_interval} iterations\\n')\n",
        "\n",
        "for iter in tqdm(range(config.max_iters)):\n",
        "    # Evaluate loss periodically\n",
        "    if iter % config.eval_interval == 0 or iter == config.max_iters - 1:\n",
        "        losses = estimate_loss(model, config)\n",
        "        print(f\"Step {iter}: train loss {losses['train']:.4f}, test loss {losses['test']:.4f}\")\n",
        "        train_losses.append(losses['train'])\n",
        "        val_losses.append(losses['test'])\n",
        "        iterations.append(iter)\n",
        "\n",
        "    # Sample a batch\n",
        "    xb, yb = get_batch_r('train', config)\n",
        "\n",
        "    # Forward pass\n",
        "    logits, loss = model(xb, yb)\n",
        "\n",
        "    # Backward pass\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    # Update learning rate\n",
        "    optimizer.param_groups[0]['lr'] = lr_iter[iter]\n",
        "    optimizer.step()\n",
        "    # save the model\n",
        "    if iter % 1000 == 0 and iter !=0 :\n",
        "      torch.save(model.state_dict(), f'model_{random_n_model}_i{iter}.pt')\n",
        "      print(\"Model saved !\")\n",
        "      #files.download(f'model_{random_n_model}_i{iter}.pt')\n",
        "      print(\"Model downloaded !\")\n",
        "\n",
        "\n",
        "print('\\nTraining complete!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9d0eed2471ca42d899ab4a8fb8e31eb9",
            "b830055b7c1b40e18a13a0fb289779fc",
            "b4c454240c174419a4c07915ae8cbfa7",
            "12fb7ae985af4942b1bed621b376d6d4",
            "2c7df8d07ce247669f675ace5076bd85",
            "e1242cb6327b4c71b1272673ebe4c4cb",
            "75d05405fede451d980aba5feaa00252",
            "34402435f7d647caa6a826c99ca3ef34",
            "35eb5d5cf87e41a0aed468d386979fe2",
            "e6b7fe56802f4f4fb8532b78796764b6",
            "eee095f12532487f845526491989a1c7"
          ]
        },
        "id": "ab_n446BGius",
        "outputId": "77894c06-887d-4e68-eccd-db64ccc2f81e"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model description\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c122865b-4712-4319-bcb5-754d55404d76\", \"model_5521.txt\", 1083)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded model description\n",
            "Starting training...\n",
            "Training for 4000 iterations\n",
            "Evaluating every 100 iterations\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d0eed2471ca42d899ab4a8fb8e31eb9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0: train loss 10.8177, test loss 10.8156\n",
            "Step 100: train loss 7.1132, test loss 7.1576\n",
            "Step 200: train loss 5.7289, test loss 5.8825\n",
            "Step 300: train loss 4.7456, test loss 5.0490\n",
            "Step 400: train loss 3.9804, test loss 4.4677\n",
            "Step 500: train loss 3.4373, test loss 4.0443\n",
            "Step 600: train loss 3.0371, test loss 3.7284\n",
            "Step 700: train loss 2.6510, test loss 3.5429\n",
            "Step 800: train loss 2.4149, test loss 3.4376\n",
            "Step 900: train loss 2.2522, test loss 3.3494\n",
            "Step 1000: train loss 2.0430, test loss 3.2937\n",
            "Model saved !\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5ec37ac6-b8f1-4520-9388-c3956494edc8\", \"model_5521_i1000.pt\", 110568561)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model downloaded !\n",
            "Step 1100: train loss 1.8529, test loss 3.3025\n",
            "Step 1200: train loss 1.6948, test loss 3.2951\n",
            "Step 1300: train loss 1.5933, test loss 3.2682\n",
            "Step 1400: train loss 1.4399, test loss 3.2357\n",
            "Step 1500: train loss 1.3522, test loss 3.1960\n",
            "Step 1600: train loss 1.2555, test loss 3.2805\n",
            "Step 1700: train loss 1.1381, test loss 3.3049\n",
            "Step 1800: train loss 1.0475, test loss 3.3459\n",
            "Step 1900: train loss 0.9809, test loss 3.3676\n",
            "Step 2000: train loss 0.9077, test loss 3.4951\n",
            "Model saved !\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d114dcf1-5906-452e-9ef4-0bc2a582aeb5\", \"model_5521_i2000.pt\", 110568561)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model downloaded !\n",
            "Step 2100: train loss 0.8045, test loss 3.4831\n",
            "Step 2200: train loss 0.7475, test loss 3.4643\n",
            "Step 2300: train loss 0.6850, test loss 3.5377\n",
            "Step 2400: train loss 0.6505, test loss 3.4941\n",
            "Step 2500: train loss 0.5766, test loss 3.5359\n",
            "Step 2600: train loss 0.5258, test loss 3.6184\n",
            "Step 2700: train loss 0.4860, test loss 3.6569\n",
            "Step 2800: train loss 0.4488, test loss 3.6589\n",
            "Step 2900: train loss 0.4111, test loss 3.6586\n",
            "Step 3000: train loss 0.3720, test loss 3.6914\n",
            "Model saved !\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_aa76bd3f-3676-48b2-a22a-123b3aa03fc2\", \"model_5521_i3000.pt\", 110568561)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model downloaded !\n",
            "Step 3100: train loss 0.3568, test loss 3.7366\n",
            "Step 3200: train loss 0.3190, test loss 3.7770\n",
            "Step 3300: train loss 0.3067, test loss 3.7030\n",
            "Step 3400: train loss 0.2872, test loss 3.7639\n",
            "Step 3500: train loss 0.2688, test loss 3.8140\n",
            "Step 3600: train loss 0.2533, test loss 3.9067\n",
            "Step 3700: train loss 0.2384, test loss 3.8282\n",
            "Step 3800: train loss 0.2265, test loss 3.9006\n",
            "Step 3900: train loss 0.2196, test loss 3.8882\n",
            "Step 3999: train loss 0.2069, test loss 3.8820\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91c72351"
      },
      "source": [
        "# gemini, pour sauver les fichiers en live sur le drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# import os\n",
        "\n",
        "# drive_path = '/content/drive/MyDrive/colab_model_checkpoints'\n",
        "# os.makedirs(drive_path, exist_ok=True)\n",
        "# print(f\"Created directory: {drive_path}\")"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "Cj8-MMo8bGWI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic"
      ],
      "metadata": {
        "id": "4EoH_CF8bNN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "figure = px.line(x=iterations, y=[train_losses, val_losses], labels={'x': 'Iteration', 'y': 'Loss'}, title='Training and Validation Loss')\n",
        "figure.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "GjBTtyabQO0C",
        "outputId": "62f622d2-aaab-4d72-fa39-82623810f5d6"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"46b14325-4509-4660-9ba7-a511b7c1be9c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"46b14325-4509-4660-9ba7-a511b7c1be9c\")) {                    Plotly.newPlot(                        \"46b14325-4509-4660-9ba7-a511b7c1be9c\",                        [{\"hovertemplate\":\"variable=wide_variable_0\\u003cbr\\u003eIteration=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"wide_variable_0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"wide_variable_0\",\"orientation\":\"h\",\"showlegend\":true,\"x\":[0,100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000,2100,2200,2300,2400,2500,2600,2700,2800,2900,3000,3100,3200,3300,3400,3500,3600,3700,3800,3900,3999],\"xaxis\":\"x\",\"y\":[10.817734718322754,7.113168239593506,5.728935718536377,4.7456159591674805,3.980350971221924,3.4372637271881104,3.03706431388855,2.6509647369384766,2.414886474609375,2.2521920204162598,2.043018102645874,1.8528884649276733,1.6948466300964355,1.593349575996399,1.4399499893188477,1.3521876335144043,1.2554631233215332,1.1380641460418701,1.0475246906280518,0.98094642162323,0.9076999425888062,0.8044546246528625,0.7474948167800903,0.6850438117980957,0.6504761576652527,0.5765756964683533,0.525827944278717,0.4859561622142792,0.4488304555416107,0.4111132025718689,0.37199515104293823,0.35684576630592346,0.31899404525756836,0.3066825866699219,0.28717222809791565,0.26880374550819397,0.25328099727630615,0.2383829951286316,0.22650432586669922,0.2195681780576706,0.20691771805286407],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"variable=wide_variable_1\\u003cbr\\u003eIteration=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"wide_variable_1\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"wide_variable_1\",\"orientation\":\"h\",\"showlegend\":true,\"x\":[0,100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000,2100,2200,2300,2400,2500,2600,2700,2800,2900,3000,3100,3200,3300,3400,3500,3600,3700,3800,3900,3999],\"xaxis\":\"x\",\"y\":[10.815618515014648,7.157586574554443,5.882526397705078,5.049041271209717,4.467708587646484,4.044325351715088,3.7284412384033203,3.542945146560669,3.4375858306884766,3.3494274616241455,3.2937238216400146,3.3024702072143555,3.295128107070923,3.268239736557007,3.2357497215270996,3.1960299015045166,3.280533790588379,3.3049428462982178,3.3459458351135254,3.3676459789276123,3.495100498199463,3.4831349849700928,3.464275598526001,3.5376830101013184,3.4940741062164307,3.5358660221099854,3.618373155593872,3.656893730163574,3.658909797668457,3.6586084365844727,3.6913962364196777,3.736582040786743,3.777017831802368,3.7030322551727295,3.7638754844665527,3.8140363693237305,3.906665563583374,3.8281965255737305,3.9005937576293945,3.888195753097534,3.8820481300354004],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Iteration\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Training and Validation Loss\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('46b14325-4509-4660-9ba7-a511b7c1be9c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate from trained model\n",
        "model.eval()\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated = model.generate(context, max_new_tokens=500, temperature=1.0, top_k=10)\n",
        "print('\\n=== Trained Model Generation ===')\n",
        "print(enc.decode(generated[0].tolist()))\n",
        "print('=' * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7LLImJRUuxF",
        "outputId": "2a771230-9752-4ead-f5b6-a72264ee45c8"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Trained Model Generation ===\n",
            "! And as they prepared for another day of arranging flowers, Lily and Larry stumbled upon an old gardening book hidden beneath a pile of wilted petals. With a twinkle in their eyes and a sense of mischief in their hearts, they decided to challenge each other to a floral design competition and see who could create the most breathtaking bouquet.  Armed with their trusty shears and a rainbow of blooms, Lily and Larry set out to showcase their floral talents to the people of Chuckleburg, transforming their shops into blooming wonderlands filled with the scent of roses and laughter. From elegant centerpieces to whimsical bouquets, they spared no expense in their quest for floral glory.  But just as they were about to unveil their masterpiece arrangements, disaster struck in the form of a mischievous squirrel who darted into the shop and nibbled on their flowers. With determination in their hearts and a dash of creativity, Lily and Larry improvised with a series of impromptu designs that had the fashionistas of Chuckleburg applauding and cheering.  In a stroke of fashion genius (or perhaps just sheer luck), they managed to unlock the most mouth and unlock the mysteries of the most stylish outfit. And as they took their final bow and innovation shared a laugh at the absurdity of it all, Lily and Larry knew that sometimes, the best barbershop experiences are the ones filled with laughter and camaraderie. In the kingdom of Ethoria, where magic danced on the breeze and legends were etched into the very fabric of reality, there existed a hidden cavern known as the Cavern of Illumination. Within its depths lay the Astral depths lay the Nexus of Dreams, a shimmering gem said to hold the power of imagination.  Drawn by tales of its enchantment and the promise of inspiration, a young dreamer named Maya ventured into the Temple of Illumination, her heart filled with wonder and anticipation. With each step, she felt the energy of the Sacred Flame drawing him closer, guiding her toward the heart of its radiant power.  As she approached the flame and felt a sense of awe wash over her, her own mind ablaze with the thirst for knowledge. With each step, she felt the ancient knowledge of the cavern, guiding her toward the heart of its mystery.  As she reached the Illuminated Manuscript, Evangeline beheld its ancient pages and felt a sense of reverence wash over her. With trembling hands, she opened the book and began to stretch\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced"
      ],
      "metadata": {
        "id": "v9m7w78tbO8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\"One day, looking over the horizon\",\n",
        "           \"In the deep forest of Mirkwood\",\n",
        "           \"The sea\"]\n",
        "answers = []\n",
        "\n",
        "for prompt in prompts :\n",
        "  p_enc = enc.encode(prompt)\n",
        "  context = torch.tensor(p_enc, dtype=torch.long, device=device).unsqueeze(0)\n",
        "  generated = model.generate(context, max_new_tokens=500, temperature=1.0, top_k=10)\n",
        "  answers.append(generated)\n",
        "  print('\\n=== Trained Model Generation ===')\n",
        "  print(enc.decode(generated[0].tolist()))\n",
        "  print('=' * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL22kNoLbR3z",
        "outputId": "5c0a32f3-57f3-4a2f-edfd-ed1df62ad2b8"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Trained Model Generation ===\n",
            "One day, looking over the horizon - the victim of an ancient magic. With her newfound clarity, Elara emerged from the portal, a beacon of hope amidst the darkness before she knew that her, she would forever be haunted by the tragic fate of all humanity. In the quaint village of Willowvale, the ticking of the clock tower echoed through the cobblestone streets, filling the air with joy and amusement. When the renowned clockmaker, Mr. Thompson found dead in his workshop, suspicion fell upon the eccentric residents harboring their own secrets.  Enter Detective Harper, a newcomer to Willowbrook with a keen eye for detail and a knack for unraveling mysteries. As she delved into the enigmatic world of clockwork, she uncovered a web of family secrets and betrayal lurking beneath the village's picturesque landscapes.  With each clue uncovered, Detective Sterling pieced together the pattern that pointed towards a sinister organization known world. Driven by an insatiable curiosity and a burning curiosity, Violet ventured into the depths of the decrepit Manor, its halls rising off tower above her like a ghostly sightings and paranormal phenomena, her only herself haunted the cobbled streets.  As she delved deeper into the heart of the library, she uncovered a dark secret that had been hidden for centuries. From ancient curses to hidden treasures, the village held many secrets waiting to be unearthed.  But as Morgan delved deeper into the mysteries of the puzzle, she realized that some mysteries were better left unsolved. For within the shadows of the vanished village, a ghostly apparitions known only as the Midnight Bloom.  On the whispering forest, Eleanor, an inexplicable pull, the current owner appeared in darkness, Madame Seraphina found herself enigma when the missing herbalist vanished before the local park. Inspector Hawthorne, but also howoming owner, guided only by tales of tragedy and restless spirit.  As they navigate through the labyrinthine corridors and winding passageways of the mansion, she felt a sense of unease settle over her—a feeling that she was being watched by unseen eyes. Strange figures lurked in the shadows, their every move adorned the walls as if the very walls themselves were alive with malevolent intent.  In a desperate bid for escape, Ella fled from the mansion, her heart pounding with fear. But even even in her eye could feel the presence of her mind, a reminder of the lives that lurked within Hill. Captain Blackthriarch of the mansion's walls, fell into the estate\n",
            "==================================================\n",
            "\n",
            "=== Trained Model Generation ===\n",
            "In the deep forest of Mirkwood's playful spirit. Miriam and Miriam's bakery, once struggling in a modern world, became a beacon of tradition. The rhythmic kneading of dough now echoed not just the creation of pastries, but the weaving together In the forgotten village of Raven's End, where the mist hung heavy and the trees whispered tales of sorrow, there stood an old church known as St. Jude's. Its weathered steeple and crumbling walls bore witness to years of neglect and abandonment, concealing the unspeakable horrors that lurked within its decaying halls.  A group of thrill-seekers, drawn by rumors of haunted places and paranormal activity, ventured into St. Jude's one moonless night. Ignoring the warnings of the locals who spoke of curses and tragic events, they crossed the threshold into darkness, their minds buzzing with excitement and trepidation.  As they explored the dimly lit corridors and shadowy chambers, a sense of unease settled over them like a heavy shroud. Strange whispers echoed through the halls, and the air was thick with the scent of decay and despair.  But it was when they stumbled upon a hidden chamber deep within the asylum that the true horror began to unfold. In the dim light of their flashlights, they discovered a series of arcane symbols etched into the walls—a language of ancient power and forbidden knowledge.  With mounting fear, the teenagers attempted to decipher the cryptic markings, but their efforts only seemed to awaken something dark and malevolent. Shadows danced upon the walls, and a sense of impending doom filled the air.  Just as all hope seemed lost, a brilliant light erupted from the symbols, banishing the darkness and filling the chamber with radiant energy. In its makeshift eyes, they reached out to claim their prize, only to be met with a chorus of groaning physical sounds.  Before they reached out to life, their movements slow but surge. The chanting intensified, morphing into a deafening chorus. It responded, and morphing into a chorus of mournful wail of voices, each one a reminder of the darkness they weren't meant to join them.  Suddenly, the world dissolved, replaced by a vast expanse of cosmic time.  With a focused mind and a heart filled with purpose, Kai emerged from the path – the sanctuary, his spirit uplifted by the knowledge that even in the darkest of times, there existed a beacon of light to guide him on his journey. In the medieval kingdom of Eld\n",
            "==================================================\n",
            "\n",
            "=== Trained Model Generation ===\n",
            "The sea. A collective dreamt of her artistry, not on the Song of Sylvana, but a master – the melody of the crystal said to hold the music itself.  Elara poured out her own memory, explaining the plight of her kingdom. The Whisperer listened with a gentle smile, her voice as soft as a summer breeze. She explained the delicate art of dream whispering – choosing the right flower, imbuing it with hope and joy, and letting its fragrance carry the dreams to the dreams of wildest dreams to the wind.  Under the command of Elara, the guide her village was fraught with peril. Along the way, she encountered mythical creatures and supernatural phenomena, each one offering her determination to uncover the secrets of the lost clan. Yet, with each step bringing her closer to her goal, she drew closer to her goal.  A rival expedition, led by the ruthless treasure hunter, was hot on her trail, intent on claiming the amulet for themselves. With danger lurking around every corner, El Dorado for themselves.  Along the way, Elara faced challenges both natural and supernatural: from cunning foes, but both both both both natural and hostile alien influence. But their greatest challenge came in the form of the jungle itself, a team of adventurers faced off against rival pirate crews who sought to claim the treasure for themselves.  In a desperate bid for survival, they fought against the formidable Crown Jewels, their courage and determination shining like a beacon in the darkness. With every move she makes and every trial she faces, she inches closer to victory, her heart filled with the hope of unlocking the portal's power.  At last, the guardians relent, their anger appeased by Eliana's bravery and respect for the grotto's ancient guardians. With a final whisper, they fade back into the shadows, leaving Eliana standing alone amidst the ruins.  Though Eliana may not have gained the power to heal the land, Eliana knows that her adventure has been a journey of discovery and enlightenment. And as she leaves the grove behind, she carries with her the knowledge that true magic lies not just in discovering new places, but in embracing the adventures forged along the way. In the forgotten town of Whispering Pines, where the fog swirled like ghostly tendrils and the moon cast an eerie glow upon the deserted streets, there stood an old mansion known as Shadowvale Manor. Its crumbling facade and broken windows hinted at a past filled with darkness\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "Ljbk20LbbKvw"
      }
    }
  ]
}