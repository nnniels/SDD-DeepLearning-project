{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqRHyNzdeXaS"
      },
      "source": [
        "# Minimal Transformer: Next Token Prediction\n",
        "\n",
        "In this notebook, we build a minimal decoder-only transformer architecture (similar to GPT) and train it on next token prediction. This follows your previous class on attention mechanisms.\n",
        "\n",
        "**Key differences from encoder-decoder transformers:**\n",
        "- Decoder-only architecture (no encoder)\n",
        "- Causal self-attention (can only attend to previous tokens)\n",
        "- Next token prediction objective\n",
        "- Character-level tokenization for simplicity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl40akxCeXaU"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "qPu9uTHTeXaU",
        "outputId": "8b6e0ca7-b502-42a6-b118-267de425b22f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "PyTorch version: 2.9.0+cu126\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import math\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check if GPU is available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using device: {device}')\n",
        "print(f'PyTorch version: {torch.__version__}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgcbOVzneXaV"
      },
      "source": [
        "## Configuration\n",
        "\n",
        "We keep the model small so it can train quickly in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Qlf2t7UpeXaV"
      },
      "outputs": [],
      "source": [
        "# Model hyperparameters\n",
        "class Config:\n",
        "    # Model architecture\n",
        "    d_model = 128          # Embedding dimension\n",
        "    n_heads = 4            # Number of attention heads\n",
        "    n_layers = 6           # Number of transformer blocks o:4\n",
        "    d_ff = 512             # Feed-forward dimension\n",
        "    dropout = 0.1          # Dropout rate\n",
        "\n",
        "    # Training\n",
        "    block_size = 64        # Maximum context length\n",
        "    batch_size = 64        # Batch size\n",
        "    learning_rate = 3e-4   # Learning rate\n",
        "    max_iters = 6000       # Training iterations o:3000\n",
        "    eval_interval = 300    # Evaluate every N iterations\n",
        "    eval_iters = 100       # Number of iterations for evaluation\n",
        "\n",
        "config = Config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR0RtnS0eXaV"
      },
      "source": [
        "## Data: Choose Your Dataset\n",
        "\n",
        "Select one of the following datasets by uncommenting the corresponding option."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "x_tHC_aheXaV",
        "outputId": "e385ec82-2c31-4993-903d-4bde7388b475",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading TinyStories dataset...\n",
            "Dataset length: 1,000,000 characters\n",
            "\n",
            "First 500 characters:\n",
            "\n",
            "Once upon a time there was a little boy named Ben. Ben loved to explore the world around him. He saw many amazing things, like beautiful vases that were on display in a store. One day, Ben was walking through the store when he came across a very special vase. When Ben saw it he was amazed!  \n",
            "He said, “Wow, that is a really amazing vase! Can I buy it?” \n",
            "The shopkeeper smiled and said, “Of course you can. You can take it home and show all your friends how amazing it is!”\n",
            "So Ben took the vase home\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# OPTION 1: TinyStories (Recommended - Modern, Simple English)\n",
        "# ============================================================\n",
        "# Download a subset of TinyStories dataset\n",
        "# print(\"Downloading TinyStories dataset...\")\n",
        "# url = 'https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2-GPT4-train.txt'\n",
        "# urllib.request.urlretrieve(url, 'dataset.txt')\n",
        "\n",
        "# # Read only first ~1MB (similar to Shakespeare size)\n",
        "# with open('dataset.txt', 'r', encoding='utf-8') as f:\n",
        "#     text = f.read(1_000_000)  # Read first 1 million characters\n",
        "\n",
        "# print(f'Dataset length: {len(text):,} characters')\n",
        "# print(f'\\nFirst 500 characters:')\n",
        "# print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "JsKL3PKueXaV",
        "outputId": "2b9522d1-6b1a-4e10-88c2-ca4f721c5930",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Shakespeare dataset...\n",
            "Dataset length: 1,115,394 characters\n",
            "\n",
            "First 500 characters:\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# OPTION 2: Shakespeare (Classic - Early Modern English)\n",
        "# ============================================================\n",
        "# Uncomment these lines to use Shakespeare instead:\n",
        "\n",
        "print(\"Downloading Shakespeare dataset...\")\n",
        "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
        "urllib.request.urlretrieve(url, 'dataset.txt')\n",
        "\n",
        "with open('dataset.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(f'Dataset length: {len(text):,} characters')\n",
        "print(f'\\nFirst 500 characters:')\n",
        "print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "Y9BUMz4xeXaW",
        "outputId": "f0df1205-ef4c-4cfe-c01b-31a586a1067f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Python code dataset...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "HTTP Error 404: Not Found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2207606133.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloading Python code dataset...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/linux/input.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dataset.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_splittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    631\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# OPTION 3: Python Code\n",
        "# ============================================================\n",
        "# Uncomment these lines to train on Python code:\n",
        "\n",
        "# print(\"Downloading Python code dataset...\")\n",
        "# url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/linux/input.txt'\n",
        "# urllib.request.urlretrieve(url, 'dataset.txt')\n",
        "\n",
        "# with open('dataset.txt', 'r', encoding='utf-8') as f:\n",
        "#     text = f.read(1_000_000)  # Read first 1 million characters\n",
        "\n",
        "# print(f'Dataset length: {len(text):,} characters')\n",
        "# print(f'\\nFirst 500 characters:')\n",
        "# print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "74BplMxLeXaW"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# OPTION 4: Modern Novel (e.g., The Adventures of Sherlock Holmes)\n",
        "# ============================================================\n",
        "# Uncomment these lines to use Sherlock Holmes:\n",
        "\n",
        "# print(\"Downloading Sherlock Holmes...\")\n",
        "# url = 'https://www.gutenberg.org/files/1661/1661-0.txt'\n",
        "# urllib.request.urlretrieve(url, 'dataset.txt')\n",
        "#\n",
        "# with open('dataset.txt', 'r', encoding='utf-8') as f:\n",
        "#     text = f.read()\n",
        "#\n",
        "# # Remove Project Gutenberg header/footer\n",
        "# start = text.find('I.')\n",
        "# end = text.find('End of the Project Gutenberg')\n",
        "# if start != -1 and end != -1:\n",
        "#     text = text[start:end]\n",
        "#\n",
        "# print(f'Dataset length: {len(text):,} characters')\n",
        "# print(f'\\nFirst 500 characters:')\n",
        "# print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "_3rMxw8TeXaW"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# OPTION 5: Wikipedia Article (Simple English Wikipedia)\n",
        "# ============================================================\n",
        "# Uncomment these lines to use Wikipedia:\n",
        "\n",
        "# print(\"Downloading Wikipedia dump...\")\n",
        "# # This is a small subset of Simple English Wikipedia\n",
        "# url = 'https://dumps.wikimedia.org/simplewiki/latest/simplewiki-latest-pages-articles.xml.bz2'\n",
        "# # Note: This requires additional processing with packages like mwparserfromhell\n",
        "# # For simplicity, you might want to manually download a few Wikipedia articles as .txt\n",
        "# # Or use a pre-processed Wikipedia dataset\n",
        "#\n",
        "# # For a quick demo, here's a manual approach:\n",
        "# text = \"\"\"Wikipedia is a free online encyclopedia.\n",
        "# [Paste several Wikipedia articles here as plain text]\n",
        "# \"\"\"\n",
        "#\n",
        "# print(f'Dataset length: {len(text):,} characters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAg1Ed3DeXaW"
      },
      "source": [
        "## Character-Level Tokenization\n",
        "\n",
        "For simplicity, we use character-level tokenization. Each unique character becomes a token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "UNRV7YDYeXaW",
        "outputId": "8096b39b-512b-484a-f8b7-49768669f89f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 65 unique characters\n",
            "Characters: \n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "\n",
            "Original: Hello, world!\n",
            "Encoded: [20, 43, 50, 50, 53, 6, 1, 61, 53, 56, 50, 42, 2]\n",
            "Decoded: Hello, world!\n"
          ]
        }
      ],
      "source": [
        "# Build vocabulary\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(f'Vocabulary size: {vocab_size} unique characters')\n",
        "print(f'Characters: {\"\".join(chars)}')\n",
        "\n",
        "# Create character-to-integer and integer-to-character mappings\n",
        "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
        "idx_to_char = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "# Encoder: string -> list of integers\n",
        "def encode(s):\n",
        "    return [char_to_idx[c] for c in s]\n",
        "\n",
        "# Decoder: list of integers -> string\n",
        "def decode(ids):\n",
        "    return ''.join([idx_to_char[i] for i in ids])\n",
        "\n",
        "# Test\n",
        "test_str = \"Hello, world!\"\n",
        "encoded = encode(test_str)\n",
        "decoded = decode(encoded)\n",
        "print(f'\\nOriginal: {test_str}')\n",
        "print(f'Encoded: {encoded}')\n",
        "print(f'Decoded: {decoded}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Qo1LW5teXaW"
      },
      "source": [
        "## Prepare Training Data\n",
        "\n",
        "Split into train and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "r7dMypRueXaW",
        "outputId": "de0a0aac-6fad-4cb8-c021-37477d51c91c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded data shape: torch.Size([1115394])\n",
            "Train data: 1,003,854 tokens\n",
            "Val data: 111,540 tokens\n"
          ]
        }
      ],
      "source": [
        "# Encode the entire dataset\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(f'Encoded data shape: {data.shape}')\n",
        "\n",
        "# Train/validation split (90/10)\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "print(f'Train data: {len(train_data):,} tokens')\n",
        "print(f'Val data: {len(val_data):,} tokens')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3RyRVUFeXaX"
      },
      "source": [
        "## Data Batching\n",
        "\n",
        "Create batches of sequences for training. Each sequence is `block_size` tokens long."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "aVGjjJw6eXaX",
        "outputId": "f5c921c2-9a61-432b-c83c-fa9e591d683e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch shape: torch.Size([64, 64])\n",
            "Target batch shape: torch.Size([64, 64])\n",
            "\n",
            "Example sequence:\n",
            "Input:  hout boot! What\n",
            "a boot is here with this exchange! Sure the gods\n",
            "Target: out boot! What\n",
            "a boot is here with this exchange! Sure the gods \n"
          ]
        }
      ],
      "source": [
        "def get_batch(split, config):\n",
        "    \"\"\"\n",
        "    Generate a small batch of data of inputs x and targets y.\n",
        "\n",
        "    Args:\n",
        "        split: 'train' or 'val'\n",
        "        config: Configuration object\n",
        "\n",
        "    Returns:\n",
        "        x: Input sequences [batch_size, block_size]\n",
        "        y: Target sequences [batch_size, block_size]\n",
        "    \"\"\"\n",
        "    data = train_data if split == 'train' else val_data\n",
        "\n",
        "    # Randomly select starting positions\n",
        "    ix = torch.randint(len(data) - config.block_size, (config.batch_size,))\n",
        "\n",
        "    # Create input and target sequences\n",
        "    x = torch.stack([data[i:i+config.block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+config.block_size+1] for i in ix])\n",
        "\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "# Test batch generation\n",
        "x_batch, y_batch = get_batch('train', config)\n",
        "print(f'Input batch shape: {x_batch.shape}')\n",
        "print(f'Target batch shape: {y_batch.shape}')\n",
        "print(f'\\nExample sequence:')\n",
        "print(f'Input:  {decode(x_batch[0].tolist())}')\n",
        "print(f'Target: {decode(y_batch[0].tolist())}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMQUsaI4eXaX"
      },
      "source": [
        "## Model Components\n",
        "\n",
        "Now we build the transformer architecture from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92Q5uwjeXaX"
      },
      "source": [
        "### 1. Multi-Head Attention\n",
        "\n",
        "You've already learned about attention! This is the causal (masked) version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "4Pc_JggyeXaX"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-head causal self-attention.\n",
        "\n",
        "    Key difference from your previous class:\n",
        "    - Uses a causal mask to prevent attending to future tokens\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, n_heads, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % n_heads == 0, \"d_model must be divisible by n_heads\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_k = d_model // n_heads  # Dimension per head\n",
        "\n",
        "        # Linear projections for Q, K, V (all heads at once)\n",
        "        self.W_q = nn.Linear(d_model, d_model, bias=True) # passage à true car supposément meilleur\n",
        "        self.W_k = nn.Linear(d_model, d_model, bias=True)\n",
        "        self.W_v = nn.Linear(d_model, d_model, bias=True)\n",
        "\n",
        "        # Output projection\n",
        "        self.W_o = nn.Linear(d_model, d_model, bias=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor [batch_size, seq_len, d_model]\n",
        "\n",
        "        Returns:\n",
        "            Output tensor [batch_size, seq_len, d_model]\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, d_model = x.shape\n",
        "\n",
        "        # Linear projections\n",
        "        Q = self.W_q(x)  # [batch_size, seq_len, d_model]\n",
        "        K = self.W_k(x)\n",
        "        V = self.W_v(x)\n",
        "\n",
        "        # Split into multiple heads and reshape\n",
        "        # [batch_size, seq_len, d_model] -> [batch_size, seq_len, n_heads, d_k]\n",
        "        # -> [batch_size, n_heads, seq_len, d_k]\n",
        "        Q = Q.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        K = K.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        V = V.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "        # Scaled dot-product attention\n",
        "        # Compute attention scores\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "        # [batch_size, n_heads, seq_len, seq_len]\n",
        "\n",
        "        # Apply causal mask (prevent attending to future tokens)\n",
        "        mask = torch.tril(torch.ones(seq_len, seq_len, device=x.device)).bool()\n",
        "        scores = scores.masked_fill(~mask, float('-inf'))\n",
        "\n",
        "        # Apply softmax\n",
        "        attn_weights = F.softmax(scores, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Apply attention to values\n",
        "        out = torch.matmul(attn_weights, V)\n",
        "        # [batch_size, n_heads, seq_len, d_k]\n",
        "\n",
        "        # Concatenate heads\n",
        "        out = out.transpose(1, 2).contiguous().view(batch_size, seq_len, d_model)\n",
        "\n",
        "        # Output projection\n",
        "        out = self.W_o(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtzEzEBceXaX"
      },
      "source": [
        "### 2. Feed-Forward Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "TegCotmAeXaX"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    Position-wise Feed-Forward Network.\n",
        "    Two linear transformations with GELU activation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(d_ff, d_model),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrXl0BdfeXaX"
      },
      "source": [
        "### 3. Transformer Block\n",
        "\n",
        "Combines attention and feed-forward with residual connections and layer normalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "golNGPNNeXaX"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A single transformer block:\n",
        "    - Multi-head attention with residual connection\n",
        "    - Feed-forward network with residual connection\n",
        "    - Layer normalization (pre-norm architecture)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(d_model)\n",
        "        self.attn = MultiHeadAttention(d_model, n_heads, dropout)\n",
        "        self.ln2 = nn.LayerNorm(d_model)\n",
        "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pre-norm architecture (more stable training)\n",
        "        # Attention with residual\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        # Feed-forward with residual\n",
        "        x = x + self.ff(self.ln2(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr1LD_n9eXaX"
      },
      "source": [
        "### 4. Complete Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "e9pl_dLteXaY"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "    \"\"\"\n",
        "    A minimal GPT-style transformer for next token prediction.\n",
        "\n",
        "    Architecture:\n",
        "    1. Token embeddings + positional embeddings\n",
        "    2. Stack of transformer blocks\n",
        "    3. Layer norm\n",
        "    4. Linear head to predict next token\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # Token embeddings\n",
        "        self.token_embedding = nn.Embedding(vocab_size, config.d_model)\n",
        "\n",
        "        # Positional embeddings (learned)\n",
        "        self.pos_embedding = nn.Embedding(config.block_size, config.d_model)\n",
        "\n",
        "        # Transformer blocks\n",
        "        self.blocks = nn.ModuleList([\n",
        "            TransformerBlock(config.d_model, config.n_heads, config.d_ff, config.dropout)\n",
        "            for _ in range(config.n_layers)\n",
        "        ])\n",
        "\n",
        "        # Final layer norm\n",
        "        self.ln_f = nn.LayerNorm(config.d_model)\n",
        "\n",
        "        # Language modeling head\n",
        "        self.lm_head = nn.Linear(config.d_model, vocab_size, bias=False)\n",
        "\n",
        "        # Weight tying (share weights between token embeddings and lm_head)\n",
        "        self.token_embedding.weight = self.lm_head.weight\n",
        "\n",
        "        # Initialize weights\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "        # Report number of parameters\n",
        "        n_params = sum(p.numel() for p in self.parameters())\n",
        "        print(f\"Number of parameters: {n_params/1e6:.2f}M\")\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            idx: Input token indices [batch_size, seq_len]\n",
        "            targets: Target token indices [batch_size, seq_len] (optional)\n",
        "\n",
        "        Returns:\n",
        "            logits: Output logits [batch_size, seq_len, vocab_size]\n",
        "            loss: Cross-entropy loss (if targets provided)\n",
        "        \"\"\"\n",
        "        batch_size, seq_len = idx.shape\n",
        "\n",
        "        # Token embeddings\n",
        "        tok_emb = self.token_embedding(idx)  # [batch_size, seq_len, d_model]\n",
        "\n",
        "        # Positional embeddings\n",
        "        pos = torch.arange(0, seq_len, dtype=torch.long, device=idx.device)\n",
        "        pos_emb = self.pos_embedding(pos)  # [seq_len, d_model]\n",
        "\n",
        "        # Add embeddings\n",
        "        x = tok_emb + pos_emb  # Broadcasting happens automatically\n",
        "\n",
        "        # Apply transformer blocks\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        # Final layer norm\n",
        "        x = self.ln_f(x)\n",
        "\n",
        "        # Language modeling head\n",
        "        logits = self.lm_head(x)  # [batch_size, seq_len, vocab_size]\n",
        "\n",
        "        # Compute loss if targets are provided\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            # Reshape for cross-entropy\n",
        "            B, T, C = logits.shape\n",
        "            logits_flat = logits.view(B * T, C)\n",
        "            targets_flat = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits_flat, targets_flat)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
        "        \"\"\"\n",
        "        Generate new tokens autoregressively.\n",
        "\n",
        "        Args:\n",
        "            idx: Starting sequence [batch_size, seq_len]\n",
        "            max_new_tokens: Number of tokens to generate\n",
        "            temperature: Sampling temperature (higher = more random)\n",
        "            top_k: If set, only sample from top k tokens\n",
        "\n",
        "        Returns:\n",
        "            Generated sequence [batch_size, seq_len + max_new_tokens]\n",
        "        \"\"\"\n",
        "        for _ in range(max_new_tokens):\n",
        "            # Crop context if needed (to fit block_size)\n",
        "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
        "\n",
        "            # Forward pass\n",
        "            logits, _ = self(idx_cond)\n",
        "\n",
        "            # Focus on last time step\n",
        "            logits = logits[:, -1, :] / temperature  # [batch_size, vocab_size]\n",
        "\n",
        "            # Optionally crop logits to only top k options\n",
        "            if top_k is not None:\n",
        "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
        "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "            # Append to sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7cO8INdeXaY"
      },
      "source": [
        "## Create Model Instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "NB1caQEYeXaY",
        "outputId": "c1b5ec35-29b0-4334-9657-1e36fe78e06a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 1.21M\n",
            "GPTModel(\n",
            "  (token_embedding): Embedding(65, 128)\n",
            "  (pos_embedding): Embedding(64, 128)\n",
            "  (blocks): ModuleList(\n",
            "    (0-5): 6 x TransformerBlock(\n",
            "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff): FeedForward(\n",
            "        (net): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "          (3): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  (lm_head): Linear(in_features=128, out_features=65, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Create model\n",
        "model = GPTModel(vocab_size, config).to(device)\n",
        "\n",
        "# Print model architecture\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7WpUSDReXaY"
      },
      "source": [
        "## Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "qdUzOKiLeXaY"
      },
      "outputs": [],
      "source": [
        "# Optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss(model, config):\n",
        "    \"\"\"\n",
        "    Estimate loss on train and validation sets.\n",
        "    \"\"\"\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(config.eval_iters)\n",
        "        for k in range(config.eval_iters):\n",
        "            X, Y = get_batch(split, config)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vPYav8veXaY"
      },
      "source": [
        "## Test Generation Before Training\n",
        "\n",
        "Let's see what the untrained model generates (should be gibberish)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "LXb0hwe0eXaY",
        "outputId": "715fb626-45c1-4eee-acc0-a4f9502d61b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Untrained Model Generation ===\n",
            "\n",
            "NNVyy?nynvguCCNTzNyCCS:dXNky R\n",
            "KgvvTxkL!&Zg:hatH!XXkRacn\n",
            "g G':\n",
            "\n",
            "RBRkSk Hee:R\n",
            "qIHZFxJEExfHRY NNEeEREEY' TM'&uZ H, xSE'ZZEcZ&ZHtaEa QQZZxxABHXHZkHHttH t BRMxta&NHYHeYNttHeP HtcuEFxEfOteD uEJFHH,FfxEFFJF\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Generate from untrained model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated = model.generate(context, max_new_tokens=200, temperature=1.0, top_k=10)\n",
        "print('\\n=== Untrained Model Generation ===')\n",
        "print(decode(generated[0].tolist()))\n",
        "print('=' * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HyKi3XzeXaZ"
      },
      "source": [
        "## Training Loop\n",
        "\n",
        "Train for a few thousand iterations. Even this limited training should show improvement!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "C_c_4azWeXaZ",
        "outputId": "be19fd0d-789f-4c62-f6b3-b0310aaba3c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539,
          "referenced_widgets": [
            "f6cb196c1b764bfd974a2afa311c3fb0",
            "ca18f01d48254b889a1ad99143d879a2",
            "8c3c01576dc943abbd9b8425e773834e",
            "e3c47e6b981a4817bf27daa3077bf3f0",
            "d081c3f03a4743ac8f57910a4739c208",
            "c73ee85bf0a245689a09aca95567b4c9",
            "d017d33392dd49a39c0a645cafd78e82",
            "3c0ce78949414ada8eb3e6392cd951a2",
            "70836def28a34ebebb85d455d2186a9d",
            "3eb7c9b1ad064412985578f48630baf6",
            "70c0948c15aa40588c0604accbfd3afc"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Training for 6000 iterations\n",
            "Evaluating every 300 iterations\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6cb196c1b764bfd974a2afa311c3fb0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0: train loss 4.2039, val loss 4.1984\n",
            "Step 300: train loss 2.3439, val loss 2.3493\n",
            "Step 600: train loss 2.0855, val loss 2.1136\n",
            "Step 900: train loss 1.8883, val loss 1.9796\n",
            "Step 1200: train loss 1.7486, val loss 1.8917\n",
            "Step 1500: train loss 1.6599, val loss 1.8125\n",
            "Step 1800: train loss 1.5974, val loss 1.7490\n",
            "Step 2100: train loss 1.5502, val loss 1.7104\n",
            "Step 2400: train loss 1.5016, val loss 1.6756\n",
            "Step 2700: train loss 1.4744, val loss 1.6593\n",
            "Step 3000: train loss 1.4453, val loss 1.6302\n",
            "Step 3300: train loss 1.4264, val loss 1.6261\n",
            "Step 3600: train loss 1.4152, val loss 1.6085\n",
            "Step 3900: train loss 1.3928, val loss 1.5904\n",
            "Step 4200: train loss 1.3827, val loss 1.5863\n",
            "Step 4500: train loss 1.3693, val loss 1.5727\n",
            "Step 4800: train loss 1.3561, val loss 1.5673\n",
            "Step 5100: train loss 1.3421, val loss 1.5561\n",
            "Step 5400: train loss 1.3311, val loss 1.5481\n",
            "Step 5700: train loss 1.3243, val loss 1.5470\n",
            "Step 5999: train loss 1.3173, val loss 1.5347\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "iterations = []\n",
        "\n",
        "print('Starting training...')\n",
        "print(f'Training for {config.max_iters} iterations')\n",
        "print(f'Evaluating every {config.eval_interval} iterations\\n')\n",
        "\n",
        "for iter in tqdm(range(config.max_iters)):\n",
        "    # Evaluate loss periodically\n",
        "    if iter % config.eval_interval == 0 or iter == config.max_iters - 1:\n",
        "        losses = estimate_loss(model, config)\n",
        "        print(f\"Step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "        train_losses.append(losses['train'])\n",
        "        val_losses.append(losses['val'])\n",
        "        iterations.append(iter)\n",
        "\n",
        "    # Sample a batch\n",
        "    xb, yb = get_batch('train', config)\n",
        "\n",
        "    # Forward pass\n",
        "    logits, loss = model(xb, yb)\n",
        "\n",
        "    # Backward pass\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "print('\\nTraining complete!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save model"
      ],
      "metadata": {
        "id": "CLLEJBxaVVZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Put the model in eval mode\n",
        "# model = model.cpu().eval()\n",
        "\n",
        "# # Script the model\n",
        "# scripted_model = torch.jit.script(model)\n",
        "\n",
        "# # Save\n",
        "# scripted_model.save(\"storyteller_model.pt\")\n",
        "\n",
        "# print(scripted_model)\n",
        "\n",
        "\n",
        "# # download model\n",
        "# from google.colab import files\n",
        "# files.download('storyteller_model.pt')\n",
        "# model.gpu()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NMH3wWCaVVBY"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD_0vqfleXaZ"
      },
      "source": [
        "## Plot Training Progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "LqGP8XgTeXaZ",
        "outputId": "52cea77b-b11b-4d26-cb39-8b9e2d2f6a4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial train loss: 4.3990\n",
            "Final train loss: 0.8727\n",
            "Improvement: 3.5263\n"
          ]
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(iterations, train_losses, label='Train Loss', marker='o')\n",
        "plt.plot(iterations, val_losses, label='Validation Loss', marker='s')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Progress')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f'Initial train loss: {train_losses[0]:.4f}')\n",
        "print(f'Final train loss: {train_losses[-1]:.4f}')\n",
        "print(f'Improvement: {train_losses[0] - train_losses[-1]:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nVqySQNeXaZ"
      },
      "source": [
        "## Test Generation After Training\n",
        "\n",
        "Now let's see what the trained model generates!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "bBZHhCcxeXaZ",
        "outputId": "ad42d662-1134-4605-c96b-596cad8e1590",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Trained Model Generation ===\n",
            "\n",
            "<|endoftext|>\n",
            "One day, a little girl named Lily went to a new place to with a stick. He had a top of beautiful music. She took the moats and found the game. He threw it was so brighter. He saw a small, food for being room and went to play with her nation, the frog reached on the park and saw a folder of big! The farmer compas and shooted the door care on the tasty and felt sure trick. She felt safe and he was singing.\n",
            "\"It's okay, Leo!\" he said, \"I'm so scared.\"\n",
            "He said, \"Of course, we can find i\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Generate from trained model\n",
        "model.eval()\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated = model.generate(context, max_new_tokens=500, temperature=1.0, top_k=10)\n",
        "print('\\n=== Trained Model Generation ===')\n",
        "print(decode(generated[0].tolist()))\n",
        "print('=' * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALD6FR6PeXaZ"
      },
      "source": [
        "## Generation with Different Seeds\n",
        "\n",
        "Try starting with different prompts. Adjust these based on your dataset!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "J1ezJoOZeXaZ",
        "outputId": "e70bc3c3-3551-424d-ceca-ee2a9b5f94d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Prompt: \"Once upon a time\" ===\n",
            "Once upon a time, there was a little boy named Tim. Tim had a great time of the slasher. He had a big farm with his magic friend. He was safe and so happy. He was sad because he knew his mom told him hand a big bird in her room.\n",
            "<|endoftext|>\n",
            "Once upon a time, there\n",
            "==================================================\n",
            "\n",
            "=== Prompt: \"One day, a little\" ===\n",
            "One day, a little bird named Tim went to the park. He played with his mom and dad liked to play all day.\n",
            "One day, Sue's mom saw the swing, the small slide and said, \"Thank you, Max!\" said Tim. He felt sorry and sad.\n",
            "He said, \"You have a great friend. It is a good tim\n",
            "==================================================\n",
            "\n",
            "=== Prompt: \"There was a\" ===\n",
            "There was a big little girl named Sue. She loved to play with his friends. One day, he would ran a little dog named Fluffy. Sam loved to play with her friends in a small house with his friends.\n",
            "One day, Sam went to the park. But then, they had a draw and some s\n",
            "==================================================\n",
            "\n",
            "=== Prompt: \"The girl was\" ===\n",
            "The girl was so scared, but she stroud, she tried to get it off the ball. He ran to the top and saw a small piece of play near the cheeser and stretion. Suddenly, Sue was safe and laughed and smiled. She asked, \"Thank you, let's find my fish sound.\"\n",
            "They ran to \n",
            "==================================================\n",
            "\n",
            "=== Prompt: \"The duck was\" ===\n",
            "The duck was scared and colorful flowers.\n",
            "<|endoftext|>\n",
            "Once upon a time, there was a little girl named Mia. She lived in a small house. She loved to play on her room and saw her street with her mom. She was scared because he wanted to be scared and play with hi\n",
            "==================================================\n",
            "\n",
            "=== Prompt: \"Duck duck duck\" ===\n",
            "Duck duck ducky to a beautiful bear in the park. He was glad that he didn't want to be kind and seek.\n",
            "The solly said, \"I am thank you for helping me. The cat looked for the bear. It is a long too. It is a sister.\"\n",
            "\"Sorry, you must make a smile. It is a big dog. It\n",
            "==================================================\n",
            "\n",
            "=== Prompt: \"One day, Jaques Hong \" ===\n",
            "One day, Jaques Hong his face with his family cars. He started to share them with his mom. She was very smart and they come out. The rock started to save him and he was a loud noise. He said, \"You have to go into the ground. You can help me, witch my mummy fell by cage.\"\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "def generate_with_prompt(prompt, max_new_tokens=300, temperature=0.8, top_k=10):\n",
        "    \"\"\"\n",
        "    Generate text starting from a prompt.\n",
        "    \"\"\"\n",
        "    context = torch.tensor([encode(prompt)], dtype=torch.long, device=device)\n",
        "    generated = model.generate(context, max_new_tokens=max_new_tokens,\n",
        "                             temperature=temperature, top_k=top_k)\n",
        "    return decode(generated[0].tolist())\n",
        "\n",
        "# Choose prompts based on your dataset:\n",
        "\n",
        "# For TinyStories:\n",
        "prompts = [\n",
        "    \"Once upon a time\",\n",
        "    \"One day, a little\",\n",
        "    \"There was a\",\n",
        "    \"The girl was\",\n",
        "    \"The duck was\",\n",
        "    \"Duck duck duck\",\n",
        "    \"One day, Jaques Hong \"\n",
        "]\n",
        "\n",
        "# For Shakespeare:\n",
        "# prompts = [\n",
        "#     \"ROMEO:\\n\",\n",
        "#     \"To be or not to be\",\n",
        "#     \"First Citizen:\\n\",\n",
        "#     \"The king\"\n",
        "# ]\n",
        "\n",
        "# For Python code:\n",
        "# prompts = [\n",
        "#     \"def \",\n",
        "#     \"import \",\n",
        "#     \"class \",\n",
        "#     \"for i in\"\n",
        "# ]\n",
        "\n",
        "# For Sherlock Holmes:\n",
        "# prompts = [\n",
        "#     \"Sherlock Holmes\",\n",
        "#     \"The detective\",\n",
        "#     \"Watson said\",\n",
        "#     \"It was a\"\n",
        "# ]\n",
        "\n",
        "for prompt in prompts:\n",
        "    print(f'\\n=== Prompt: \"{prompt}\" ===')\n",
        "    generated_text = generate_with_prompt(prompt, max_new_tokens=250, temperature=0.7, top_k=10)\n",
        "    print(generated_text)\n",
        "    print('=' * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcbOR0dteXaZ"
      },
      "source": [
        "## Temperature and Top-K Effects\n",
        "\n",
        "Experiment with different generation parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "PATeFcuCeXaZ",
        "outputId": "2bea46d7-b14e-4d89-cd20-3ac8956d9928",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Low Temperature (0.5) - More focused ===\n",
            "Once upon a time, there was a little girl named Lily. She had a big hurt of her hand. She looked at the park and the story on the corner and felt sad. The bird was no\n",
            "\n",
            "=== Medium Temperature (1.0) - Balanced ===\n",
            "Once upon a time, there was a little girl named Abby went to be friends. They was very happy, but he kindnew the forest, he stroved around the farm. Mom was so sad. \n",
            "\n",
            "\n",
            "=== High Temperature (1.5) - More random ===\n",
            "Once upon a time, there was a face. The could not water thing stillow.\n",
            "Tom righf that we hunks a suge. She does not so are this toweers of appain. One day, Tim's favo\n"
          ]
        }
      ],
      "source": [
        "# Choose a prompt from your dataset:\n",
        "prompt = \"Once upon a time\"  # For TinyStories\n",
        "# prompt = \"ROMEO:\\n\"  # For Shakespeare\n",
        "# prompt = \"def \"  # For Python code\n",
        "# prompt = \"Sherlock Holmes\"  # For Sherlock Holmes\n",
        "\n",
        "print(\"=== Low Temperature (0.5) - More focused ===\")\n",
        "print(generate_with_prompt(prompt, max_new_tokens=150, temperature=0.5, top_k=10))\n",
        "\n",
        "print(\"\\n=== Medium Temperature (1.0) - Balanced ===\")\n",
        "print(generate_with_prompt(prompt, max_new_tokens=150, temperature=1.0, top_k=10))\n",
        "\n",
        "print(\"\\n=== High Temperature (1.5) - More random ===\")\n",
        "print(generate_with_prompt(prompt, max_new_tokens=150, temperature=1.5, top_k=10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vguoqWQ1eXaZ"
      },
      "source": [
        "## Analysis: What Did We Learn?\n",
        "\n",
        "Even with this minimal training:\n",
        "1. **Structure**: The model learns basic text structure (words, punctuation, capitalization)\n",
        "2. **Patterns**: It picks up on common patterns in the data\n",
        "   - TinyStories: narrative structure, character actions\n",
        "   - Shakespeare: dialogue format, character names\n",
        "   - Python code: syntax, indentation, function structure\n",
        "3. **Context**: The causal attention allows it to use context from previous tokens\n",
        "4. **Limitations**: It's not perfect - longer coherence requires much more training\n",
        "\n",
        "**Key Architecture Points:**\n",
        "- **Decoder-only**: Unlike encoder-decoder models for translation, this is decoder-only (like GPT)\n",
        "- **Causal attention**: The mask ensures we only attend to past tokens\n",
        "- **Next token prediction**: Simple but powerful objective\n",
        "- **Scalability**: This same architecture scales to billions of parameters (GPT-3, GPT-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzmVKYZheXaZ"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "To improve this model further, try one or multiple of the following:\n",
        "1. Train for more iterations (10k-50k)\n",
        "2. Increase model size (more layers, larger d_model)\n",
        "3. Combine datasets together to have more text (be careful of style differences)\n",
        "4. Add learning rate scheduling\n",
        "5. Modify the optimizer and hyperparameters\n",
        "6. Implement gradient clipping\n",
        "7. Try different tokenization (BPE instead of character-level)\n",
        "8. Add dropout for better regularization\n",
        "9. Experiment with different attention patterns (e.g., Flash Attention)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVFo9a-HeXaa"
      },
      "source": [
        "## Save Model (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "mdQWTUaleXaa",
        "outputId": "a3988e1f-8392-4bb3-e1e6-2b8d1c70c317",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to minimal_transformer_checkpoint.pt\n"
          ]
        }
      ],
      "source": [
        "# Save model checkpoint\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'config': config,\n",
        "    'vocab_size': vocab_size,\n",
        "    'char_to_idx': char_to_idx,\n",
        "    'idx_to_char': idx_to_char,\n",
        "}, 'minimal_transformer_checkpoint.pt')\n",
        "\n",
        "print('Model saved to minimal_transformer_checkpoint.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l1wz2CPeXaa"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, we built a minimal transformer from scratch:\n",
        "- Character-level tokenization\n",
        "- Causal multi-head attention\n",
        "- Position-wise feed-forward networks\n",
        "- Residual connections and layer normalization\n",
        "- Next token prediction training\n",
        "- Autoregressive generation\n",
        "\n",
        "This architecture is the foundation of modern LLMs like GPT!\n",
        "\n",
        "**Questions to consider:**\n",
        "1. Why is causal masking necessary for language generation?\n",
        "2. What would happen without positional embeddings?\n",
        "3. How does temperature affect generation quality?\n",
        "4. What are the tradeoffs between character-level and subword tokenization?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f6cb196c1b764bfd974a2afa311c3fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca18f01d48254b889a1ad99143d879a2",
              "IPY_MODEL_8c3c01576dc943abbd9b8425e773834e",
              "IPY_MODEL_e3c47e6b981a4817bf27daa3077bf3f0"
            ],
            "layout": "IPY_MODEL_d081c3f03a4743ac8f57910a4739c208"
          }
        },
        "ca18f01d48254b889a1ad99143d879a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c73ee85bf0a245689a09aca95567b4c9",
            "placeholder": "​",
            "style": "IPY_MODEL_d017d33392dd49a39c0a645cafd78e82",
            "value": "100%"
          }
        },
        "8c3c01576dc943abbd9b8425e773834e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c0ce78949414ada8eb3e6392cd951a2",
            "max": 6000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70836def28a34ebebb85d455d2186a9d",
            "value": 6000
          }
        },
        "e3c47e6b981a4817bf27daa3077bf3f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3eb7c9b1ad064412985578f48630baf6",
            "placeholder": "​",
            "style": "IPY_MODEL_70c0948c15aa40588c0604accbfd3afc",
            "value": " 6000/6000 [02:41&lt;00:00, 49.96it/s]"
          }
        },
        "d081c3f03a4743ac8f57910a4739c208": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c73ee85bf0a245689a09aca95567b4c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d017d33392dd49a39c0a645cafd78e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c0ce78949414ada8eb3e6392cd951a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70836def28a34ebebb85d455d2186a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3eb7c9b1ad064412985578f48630baf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70c0948c15aa40588c0604accbfd3afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}